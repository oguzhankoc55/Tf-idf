{fenge}
math;0108096	geometrically uniform frames	we introduce a new class of frames with strong symmetry properties calledgeometrically uniform frames (gu), that are defined over an abelian group ofunitary matrices and are generated by a single generating vector. the notion ofgu frames is then extended to compound gu (cgu) frames which are generated byan abelian group of unitary matrices using multiple generating vectors.  the dual frame vectors and canonical tight frame vectors associated with guframes are shown to be gu and therefore generated by a single generatingvector, which can be computed very efficiently using a fourier transformdefined over the generating group of the frame. similarly, the dual framevectors and canonical tight frame vectors associated with cgu frames are shownto be cgu.  the impact of removing single or multiple elements from a gu frame isconsidered. a systematic method for constructing optimal gu frames from a givenset of frame vectors that are not gu is also developed. finally, the euclideandistance properties of gu frames are discussed and conditions are derived onthe abelian group of unitary matrices to yield gu frames with strictly positivedistance spectrum irrespective of the generating vector.
{fenge}
math;0511209	a constructive inversion framework for twisted convolution	in this paper we develop constructive invertibility conditions for thetwisted convolution. our approach is based on splitting the twisted convolutionwith rational parameters into a finite number of weighted convolutions, whichcan be interpreted as another twisted convolution on a finite cyclic group. inanalogy with the twisted convolution of finite discrete signals, we derive ananti-homomorphism between the sequence space and a suitable matrix algebrawhich preserves the algebraic structure. in this way, the problem reduces tothe analysis of finite matrices whose entries are sequences supported oncorresponding cosets. the invertibility condition then follows from cramer'srule and wiener's lemma for this special class of matrices. the problem resultsfrom a well known approach of studying the invertibility properties of thegabor frame operator in the rational case. the presented approach gives furtherinsights into gabor frames. in particular, it can be applied for both thecontinuous (on $\rd$) and the finite discrete setting. in the latter case, weobtain algorithmic schemes for directly computing the inverse of gaborframe-type matrices equivalent to those known in the literature.
{fenge}
0902.4291	from theory to practice: sub-nyquist sampling of sparse wideband analog  signals	conventional sub-nyquist sampling methods for analog signals exploit priorinformation about the spectral support. in this paper, we consider thechallenging problem of blind sub-nyquist sampling of multiband signals, whoseunknown frequency support occupies only a small portion of a wide spectrum. ourprimary design goals are efficient hardware implementation and lowcomputational load on the supporting digital processing. we propose a system,named the modulated wideband converter, which first multiplies the analogsignal by a bank of periodic waveforms. the product is then lowpass filteredand sampled uniformly at a low rate, which is orders of magnitude smaller thannyquist. perfect recovery from the proposed samples is achieved under certainnecessary and sufficient conditions. we also develop a digital architecture,which allows either reconstruction of the analog input, or processing of anyband of interest at a low rate, that is, without interpolating to the highnyquist rate. numerical simulations demonstrate many engineering aspects:robustness to noise and mismodeling, potential hardware simplifications,realtime performance for signals with time-varying support and stability toquantization effects. we compare our system with two previous approaches:periodic nonuniform sampling, which is bandwidth limited by existing hardwaredevices, and the random demodulator, which is restricted to discrete multitonesignals and has a high computational load. in the broader context of nyquistsampling, our scheme has the potential to break through the bandwidth barrierof state-of-the-art analog conversion technologies such as interleavedconverters.
{fenge}
0903.1283	covariance estimation in decomposable gaussian graphical models	graphical models are a framework for representing and exploiting priorconditional independence structures within distributions using graphs. in thegaussian case, these models are directly related to the sparsity of the inversecovariance (concentration) matrix and allow for improved covariance estimationwith lower computational complexity. we consider concentration estimation withthe mean-squared error (mse) as the objective, in a special type of model knownas decomposable. this model includes, for example, the well known bandedstructure and other cases encountered in practice. our first contribution isthe derivation and analysis of the minimum variance unbiased estimator (mvue)in decomposable graphical models. we provide a simple closed form solution tothe mvue and compare it with the classical maximum likelihood estimator (mle)in terms of performance and complexity. next, we extend the celebrated stein'sunbiased risk estimate (sure) to graphical models. using sure, we prove thatthe mse of the mvue is always smaller or equal to that of the biased mle, andthat the mvue itself is dominated by other approaches. in addition, we proposethe use of sure as a constructive mechanism for deriving new covarianceestimators. similarly to the classical mle, all of our proposed estimators havesimple closed form solutions but result in a significant reduction in mse.
{fenge}
quant-ph;0205178	designing optimal quantum detectors via semidefinite programming	we consider the problem of designing an optimal quantum detector to minimizethe probability of a detection error when distinguishing between a collectionof quantum states, represented by a set of density operators. we show that thedesign of the optimal detector can be formulated as a semidefinite programmingproblem. based on this formulation, we derive a set of necessary and sufficientconditions for an optimal quantum measurement. we then show that the optimalmeasurement can be found by solving a standard (convex) semidefinite programfollowed by the solution of a set of linear equations or, at worst, a standardlinear programming problem. by exploiting the many well-known algorithms forsolving semidefinite programs, which are guaranteed to converge to the globaloptimum, the optimal measurement can be computed very efficiently in polynomialtime.  using the semidefinite programming formulation, we also show that the rank ofeach optimal measurement operator is no larger than the rank of thecorresponding density operator. in particular, if the quantum state ensemble isa pure-state ensemble consisting of (not necessarily independent) rank-onedensity operators, then we show that the optimal measurement is a pure-statemeasurement consisting of rank-one measurement operators.
{fenge}
quant-ph;0206093	a semidefinite programming approach to optimal unambiguous  discrimination of quantum states	in this paper we consider the problem of unambiguous discrimination between aset of linearly independent pure quantum states. we show that the design of theoptimal measurement that minimizes the probability of an inconclusive resultcan be formulated as a semidefinite programming problem. based on thisformulation, we develop a set of necessary and sufficient conditions for anoptimal quantum measurement. we show that the optimal measurement can becomputed very efficiently in polynomial time by exploiting the many well-knownalgorithms for solving semidefinite programs, which are guaranteed to convergeto the global optimum.  using the general conditions for optimality, we derive necessary andsufficient conditions so that the measurement that results in an equalprobability of an inconclusive result for each one of the quantum states isoptimal. we refer to this measurement as the equal-probability measurement(epm). we then show that for any state set, the prior probabilities of thestates can be chosen such that the epm is optimal.  finally, we consider state sets with strong symmetry properties and equalprior probabilities for which the epm is optimal. we first considergeometrically uniform state sets that are defined over a group of unitarymatrices and are generated by a single generating vector. we then considercompound geometrically uniform state sets which are generated by a group ofunitary matrices using multiple generating vectors, where the generatingvectors satisfy a certain (weighted) norm constraint.
{fenge}
quant-ph;0211111	optimal detection of symmetric mixed quantum states	we develop a sufficient condition for the least-squares measurement (lsm), orthe square-root measurement, to minimize the probability of a detection errorwhen distinguishing between a collection of mixed quantum states. using thiscondition we derive the optimal measurement for state sets with a broad classof symmetries.  we first consider geometrically uniform (gu) state sets with a possiblynonabelian generating group, and show that if the generator satisfies a certainconstraint, then the lsm is optimal. in particular, for pure-state gu ensemblesthe lsm is shown to be optimal. for arbitrary gu state sets we show that theoptimal measurement operators are gu with generator that can be computed veryefficiently in polynomial time, within any desired accuracy.  we then consider compound gu (cgu) state sets which consist of subsets thatare gu. when the generators satisfy a certain constraint, the lsm is againoptimal. for arbitrary cgu state sets the optimal measurement operators areshown to be cgu with generators that can be computed efficiently in polynomialtime.
{fenge}
0904.0494	average case analysis of multichannel sparse recovery using convex  relaxation	in this paper, we consider recovery of jointly sparse multichannel signalsfrom incomplete measurements. several approaches have been developed to recoverthe unknown sparse vectors from the given observations, including thresholding,simultaneous orthogonal matching pursuit (somp), and convex relaxation based ona mixed matrix norm. typically, worst-case analysis is carried out in order toanalyze conditions under which the algorithms are able to recover any jointlysparse set of vectors. however, such an approach is not able to provideinsights into why joint sparse recovery is superior to applying standard sparsereconstruction methods to each channel individually. previous work consideredan average case analysis of thresholding and somp by imposing a probabilitymodel on the measured signals. in this paper, our main focus is on analysis ofconvex relaxation techniques. in particular, we focus on the mixed l_2,1approach to multichannel recovery. we show that under a very mild condition onthe sparsity and on the dictionary characteristics, measured for example by thecoherence, the probability of recovery failure decays exponentially in thenumber of channels. this demonstrates that most of the time, multichannelsparse recovery is indeed superior to single channel methods. our probabilitybounds are valid and meaningful even for a small number of signals. using thetools we develop to analyze the convex relaxation method, we also tighten theprevious bounds for thresholding and somp.
{fenge}
quant-ph;0601010	optimal encoding of classical information in a quantum medium	we investigate optimal encoding and retrieval of digital data, when thestorage/communication medium is described by quantum mechanics. we assume anm-ary alphabet with arbitrary prior distribution, and an n-dimensional quantumsystem. under these constraints, we seek an encoding-retrieval setup, comprisedof code-states and a quantum measurement, which maximizes the probability ofcorrect detection. in our development, we consider two cases. in the first, themeasurement is predefined and we seek the optimal code-states. in the second,optimization is performed on both the code-states and the measurement.  we show that one cannot outperform `pseudo-classical transmission', in whichwe transmit n symbols with orthogonal code-states, and discard the remainingsymbols. however, such pseudo-classical transmission is not the only optimum.we fully characterize the collection of optimal setups, and briefly discuss thelinks between our findings and applications such as quantum key distributionand quantum computing. we conclude with a number of results concerning thedesign under an alternative optimality criterion, the worst-case posteriorprobability, which serves as a measure of the retrieval reliability.
{fenge}
0905.2429	time delay estimation from low rate samples: a union of subspaces  approach	time delay estimation arises in many applications in which a multipath mediumhas to be identified from pulses transmitted through the channel. variousapproaches have been proposed in the literature to identify time delaysintroduced by multipath environments. however, these methods either operate onthe analog received signal, or require high sampling rates in order to achievereasonable time resolution. in this paper, our goal is to develop a unifiedapproach to time delay estimation from low rate samples of the output of amultipath channel. our methods result in perfect recovery of the multipathdelays from samples of the channel output at the lowest possible rate, even inthe presence of overlapping transmitted pulses. this rate depends only on thenumber of multipath components and the transmission rate, but not on thebandwidth of the probing signal. in addition, our development allows for avariety of different sampling methods. by properly manipulating the low-ratesamples, we show that the time delays can be recovered using the well-knownesprit algorithm. combining results from sampling theory with those obtained inthe context of direction of arrival estimation methods, we develop necessaryand sufficient conditions on the transmitted pulse and the sampling functionsin order to ensure perfect recovery of the channel parameters at the minimalpossible rate. our results can be viewed in a broader context, as a samplingtheorem for analog signals defined over an infinite union of subspaces.
{fenge}
0907.3296	non-invertible gabor transforms	time-frequency analysis, such as the gabor transform, plays an important rolein many signal processing applications. the redundancy of such representationsis often directly related to the computational load of any algorithm operatingin the transform domain. to reduce complexity, it may be desirable to increasethe time and frequency sampling intervals beyond the point where the transformis invertible, at the cost of an inevitable recovery error. in this paper weinitiate the study of recovery procedures for non-invertible gaborrepresentations. we propose using fixed analysis and synthesis windows, chosene.g. according to implementation constraints, and to process the gaborcoefficients prior to synthesis in order to shape the reconstructed signal. wedevelop three methods to tackle this problem. the first follows from theconsistency requirement, namely that the recovered signal has the same gaborrepresentation as the input signal. the second, is based on the minimization ofa worst-case error criterion. last, we develop a recovery technique based onthe assumption that the input signal lies in some subspace of $l_2$. we showthat for each of the criteria, the manipulation of the transform coefficientsamounts to a 2d twisted convolution operation, which we show how to performusing a filter-bank. when the under-sampling factor is an integer, theprocessing reduces to standard 2d convolution. we provide simulation results todemonstrate the advantages and weaknesses of each of the algorithms.
{fenge}
0907.4698	shrinkage algorithms for mmse covariance estimation	we address covariance estimation in the sense of minimum mean-squared error(mmse) for gaussian samples. specifically, we consider shrinkage methods whichare suitable for high dimensional problems with a small number of samples(large p small n). first, we improve on the ledoit-wolf (lw) method byconditioning on a sufficient statistic. by the rao-blackwell theorem, thisyields a new estimator called rblw, whose mean-squared error dominates that oflw for gaussian variables. second, to further reduce the estimation error, wepropose an iterative approach which approximates the clairvoyant shrinkageestimator. convergence of this iterative method is established and a closedform expression for the limit is determined, which is referred to as the oracleapproximating shrinkage (oas) estimator. both rblw and oas estimators havesimple expressions and are easily implemented. although the two methods aredeveloped from different persepctives, their structure is identical up tospecified constants. the rblw estimator provably dominates the lw method.numerical simulations demonstrate that the oas approach can perform even betterthan rblw, especially when n is much less than p. we also demonstrate theperformance of these techniques in the context of adaptive beamforming.
{fenge}
0911.0519	xampling: signal acquisition and processing in union of subspaces	we introduce xampling, a unified framework for signal acquisition andprocessing of signals in a union of subspaces. the main functions of thisframework are two. analog compression that narrows down the input bandwidthprior to sampling with commercial devices. a nonlinear algorithm then detectsthe input subspace prior to conventional signal processing. a representativeunion model of spectrally-sparse signals serves as a test-case to study thesexampling functions. we adopt three metrics for the choice of analogcompression: robustness to model mismatch, required hardware accuracy andsoftware complexities. we conduct a comprehensive comparison between twosub-nyquist acquisition strategies for spectrally-sparse signals, the randomdemodulator and the modulated wideband converter (mwc), in terms of thesemetrics and draw operative conclusions regarding the choice of analogcompression. we then address lowrate signal processing and develop an algorithmfor that purpose that enables convenient signal processing at sub-nyquist ratesfrom samples obtained by the mwc. we conclude by showing that a variety ofother sampling approaches for different union classes fit nicely into ourframework.
{fenge}
0912.2495	xampling: analog to digital at sub-nyquist rates	we present a sub-nyquist analog-to-digital converter of wideband inputs. ourcircuit realizes the recently proposed modulated wideband converter, which is aflexible platform for sampling signals according to their actual bandwidthoccupation. the theoretical work enables, for example, a sub-nyquist widebandreceiver, which has no prior information on the transmitter carrier positions.our design supports input signals with 2 ghz nyquist rate and 120 mhz spectrumoccupancy, with arbitrary transmission frequencies. the sampling rate is as lowas 280 mhz. to the best of our knowledge, this is the first reported widebandhardware for sub-nyquist conversion. furthermore, the modular design is provento compete with state-of-the-art nyquist adcs in terms of resolution bits andfull-scale range. we describe the various circuit design considerations, withan emphasis on the nonordinary challenges the converter introduces: mixing asignal with a multiple set of sinusoids, rather than a single local oscillator,and generation of highly-transient periodic waveforms, with transient intervalson the order of the nyquist rate. a series of hardware experiments validatesthe design and demonstrate sub-nyquist sampling.
{fenge}
1002.2586	blind compressed sensing	the fundamental principle underlying compressed sensing is that a signal,which is sparse under some basis representation, can be recovered from a smallnumber of linear measurements. however, prior knowledge of the sparsity basisis essential for the recovery process. this work introduces the concept ofblind compressed sensing, which avoids the need to know the sparsity basis inboth the sampling and the recovery process. we suggest three possibleconstraints on the sparsity basis that can be added to the problem in order tomake its solution unique. for each constraint we prove conditions foruniqueness, and suggest a simple method to retrieve the solution. under theuniqueness conditions, and as long as the signals are sparse enough, wedemonstrate through simulations that without knowing the sparsity basis ourmethods can achieve results similar to those of standard compressed sensing,which relay on prior knowledge of the sparsity basis. this offers a generalsampling and reconstruction system that fits all sparse signals, regardless ofthe sparsity basis, under the conditions and constraints presented in thiswork.
{fenge}
1003.0400	collaborative hierarchical sparse modeling	sparse modeling is a powerful framework for data analysis and processing.traditionally, encoding in this framework is done by solving an l_1-regularizedlinear regression problem, usually called lasso. in this work we first combinethe sparsity-inducing property of the lasso model, at the individual featurelevel, with the block-sparsity property of the group lasso model, where sparsegroups of features are jointly encoded, obtaining a sparsity patternhierarchically structured. this results in the hierarchical lasso, which showsimportant practical modeling advantages. we then extend this approach to thecollaborative case, where a set of simultaneously coded signals share the samesparsity pattern at the higher (group) level but not necessarily at the lowerone. signals then share the same active groups, or classes, but not necessarilythe same active set. this is very well suited for applications such as sourceseparation. an efficient optimization procedure, which guarantees convergenceto the global optimum, is developed for these new models. the underlyingpresentation of the new framework and optimization approach is complementedwith experimental examples and preliminary theoretical results.
{fenge}
1003.2822	innovation rate sampling of pulse streams with application to ultrasound  imaging	signals comprised of a stream of short pulses appear in many applicationsincluding bio-imaging and radar. the recent finite rate of innovationframework, has paved the way to low rate sampling of such pulses by noticingthat only a small number of parameters per unit time are needed to fullydescribe these signals. unfortunately, for high rates of innovation, existingsampling schemes are numerically unstable. in this paper we propose a generalsampling approach which leads to stable recovery even in the presence of manypulses. we begin by deriving a condition on the sampling kernel which allowsperfect reconstruction of periodic streams from the minimal number of samples.we then design a compactly supported class of filters, satisfying thiscondition. the periodic solution is extended to finite and infinite streams,and is shown to be numerically stable even for a large number of pulses. highnoise robustness is also demonstrated when the delays are sufficientlyseparated. finally, we process ultrasound imaging data using our techniques,and show that substantial rate reduction with respect to traditional ultrasoundsampling schemes can be achieved.
{fenge}
1004.4529	rank awareness in joint sparse recovery	in this paper we revisit the sparse multiple measurement vector (mmv) problemwhere the aim is to recover a set of jointly sparse multichannel vectors fromincomplete measurements. this problem has received increasing interest as anextension of the single channel sparse recovery problem which lies at the heartof the emerging field of compressed sensing. however the sparse approximationproblem has origins which include links to the field of array signal processingwhere we find the inspiration for a new family of mmv algorithms based on themusic algorithm. we highlight the role of the rank of the coefficient matrix xin determining the difficulty of the recovery problem. we derive the necessaryand sufficient conditions for the uniqueness of the sparse mmv solution, whichindicates that the larger the rank of x the less sparse x needs to be to ensureuniqueness. we also show that the larger the rank of x the less thecomputational effort required to solve the mmv problem through a combinatorialsearch. in the second part of the paper we consider practical suboptimalalgorithms for solving the sparse mmv problem. we examine the rank awareness ofpopular algorithms such as somp and mixed norm minimization techniques and showthem to be rank blind in terms of worst case analysis. we then consider afamily of greedy algorithms that are rank aware. the simplest such algorithm isa discrete version of music and is guaranteed to recover the sparse vectors inthe full rank mmv case under mild conditions. we extend this idea to develop arank aware pursuit algorithm that naturally reduces to order recursive matchingpursuit (ormp) in the single measurement case and also provides guaranteedrecovery in the full rank multi-measurement case. numerical simulationsdemonstrate that the rank aware algorithms are significantly better thanexisting algorithms in dealing with multiple measurements.
{fenge}
1004.5070	multichannel sampling of pulse streams at the rate of innovation	we consider minimal-rate sampling schemes for infinite streams of delayed andweighted versions of a known pulse shape. the minimal sampling rate for theseparametric signals is referred to as the rate of innovation and is equal to thenumber of degrees of freedom per unit time. although sampling of infinite pulsestreams was treated in previous works, either the rate of innovation was notachieved, or the pulse shape was limited to diracs. in this paper we propose amultichannel architecture for sampling pulse streams with arbitrary shape,operating at the rate of innovation. our approach is based on modulating theinput signal with a set of properly chosen waveforms, followed by a bank ofintegrators. this architecture is motivated by recent work on sub-nyquistsampling of multiband signals. we show that the pulse stream can be recoveredfrom the proposed minimal-rate samples using standard tools taken from spectralestimation in a stable way even at high rates of innovation. in addition, weaddress practical implementation issues, such as reduction of hardwarecomplexity and immunity to failure in the sampling channels. the resultingscheme is flexible and exhibits better noise robustness than previousapproaches.
{fenge}
1005.0202	dictionary optimization for block-sparse representations	recent work has demonstrated that using a carefully designed dictionaryinstead of a predefined one, can improve the sparsity in jointly representing aclass of signals. this has motivated the derivation of learning methods fordesigning a dictionary which leads to the sparsest representation for a givenset of signals. in some applications, the signals of interest can have furtherstructure, so that they can be well approximated by a union of a small numberof subspaces (e.g., face recognition and motion segmentation). this implies theexistence of a dictionary which enables block-sparse representations of theinput signals once its atoms are properly sorted into blocks. in this paper, wepropose an algorithm for learning a block-sparsifying dictionary of a given setof signals. we do not require prior knowledge on the association of signalsinto groups (subspaces). instead, we develop a method that automaticallydetects the underlying block structure. this is achieved by iterativelyalternating between updating the block structure of the dictionary and updatingthe dictionary atoms to better fit the data. our experiments show that forblock-sparse data the proposed algorithm significantly improves the dictionaryrecovery ability and lowers the representation error compared to dictionarylearning methods that do not employ block structure.
{fenge}
1005.5697	unbiased estimation of a sparse vector in white gaussian noise	we consider unbiased estimation of a sparse nonrandom vector corrupted byadditive white gaussian noise. we show that while there are infinitely manyunbiased estimators for this problem, none of them has uniformly minimumvariance. therefore, we focus on locally minimum variance unbiased (lmvu)estimators. we derive simple closed-form lower and upper bounds on the varianceof lmvu estimators or, equivalently, on the barankin bound (bb). our boundsallow an estimation of the threshold region separating the low-snr and high-snrregimes, and they indicate the asymptotic behavior of the bb at high snr. wealso develop numerical lower and upper bounds which are tighter than theclosed-form bounds and thus characterize the bb more accurately. numericalstudies compare our characterization of the bb with established biasedestimation schemes, and demonstrate that while unbiased estimators performpoorly at low snr, they may perform better than biased estimators at high snr.an interesting conclusion of our analysis is that the high-snr behavior of thebb depends solely on the value of the smallest nonzero component of the sparsevector, and that this type of dependence is also exhibited by the performanceof certain practical estimators.
{fenge}
1008.0851	identification of parametric underspread linear systems and  super-resolution radar	identification of time-varying linear systems, which introduce bothtime-shifts (delays) and frequency-shifts (doppler-shifts), is a central taskin many engineering applications. this paper studies the problem ofidentification of underspread linear systems (ulss), whose responses lie withina unit-area region in the delay doppler space, by probing them with a knowninput signal. it is shown that sufficiently-underspread parametric linearsystems, described by a finite set of delays and doppler-shifts, areidentifiable from a single observation as long as the time bandwidth product ofthe input signal is proportional to the square of the total number of delaydoppler pairs in the system. in addition, an algorithm is developed thatenables identification of parametric ulss from an input train of pulses inpolynomial time by exploiting recent results on sub-nyquist sampling for timedelay estimation and classical results on recovery of frequencies from a sum ofcomplex exponentials. finally, application of these results to super-resolutiontarget detection using radar is discussed. specifically, it is shown that theproposed procedure allows to distinguish between multiple targets with veryclose proximity in the delay doppler space, resulting in a resolution thatsubstantially exceeds that of standard matched-filtering based techniqueswithout introducing leakage effects inherent in recently proposed compressedsensing-based radar methods.
{fenge}
1009.2221	performance bounds and design criteria for estimating finite rate of  innovation signals	in this paper, we consider the problem of estimating finite rate ofinnovation (fri) signals from noisy measurements, and specifically analyze theinteraction between fri techniques and the underlying sampling methods. wefirst obtain a fundamental limit on the estimation accuracy attainableregardless of the sampling method. next, we provide a bound on the performanceachievable using any specific sampling approach. essential differences betweenthe noisy and noise-free cases arise from this analysis. in particular, weidentify settings in which noise-free recovery techniques deterioratesubstantially under slight noise levels, thus quantifying the numericalinstability inherent in such methods. this instability, which is only presentin some families of fri signals, is shown to be related to a specific type ofstructure, which can be characterized by viewing the signal model as a union ofsubspaces. finally, we develop a methodology for choosing the optimal samplingkernels based on a generalization of the karhunen--lo\`eve transform. theresults are illustrated for several types of time-delay estimation problems.
{fenge}
1010.3132	sub-nyquist sampling of short pulses	we develop sub-nyquist sampling systems for analog signals comprised ofseveral, possibly overlapping, finite duration pulses with unknown shapes andtime positions. efficient sampling schemes when either the pulse shape or thelocations of the pulses are known have been previously developed. to the bestof our knowledge, stable and low-rate sampling strategies for continuoussignals that are superpositions of unknown pulses without knowledge of thepulse locations have not been derived. the goal in this paper is to fill thisgap. we propose a multichannel scheme based on gabor frames that exploits thesparsity of signals in time and enables sampling multipulse signals atsub-nyquist rates. moreover, if the signal is additionally essentiallymultiband, then the sampling scheme can be adapted to lower the sampling ratewithout knowing the band locations. we show that, with proper preprocessing,the necessary gabor coefficients, can be recovered from the samples usingstandard methods of compressed sensing. in addition, we provide error estimateson the reconstruction and analyze the proposed architecture in the presence ofnoise.
{fenge}
1010.5734	exploiting statistical dependencies in sparse representations for signal  recovery	signal modeling lies at the core of numerous signal and image processingapplications. a recent approach that has drawn considerable attention is sparserepresentation modeling, in which the signal is assumed to be generated as acombination of a few atoms from a given dictionary. in this work we consider abayesian setting and go beyond the classic assumption of independence betweenthe atoms. the main goal of this paper is to introduce a statistical model thattakes such dependencies into account and show how this model can be used forsparse signal recovery. we follow the suggestion of two recent works and assumethat the sparsity pattern is modeled by a boltzmann machine, a commonly usedgraphical model. for general dependency models, exact map and mmse estimationof the sparse representation becomes computationally complex. to simplify thecomputations, we propose greedy approximations of the map and mmse estimators.we then consider a special case in which exact map is feasible, by assumingthat the dictionary is unitary and the dependency model corresponds to acertain sparse graph. exploiting this structure, we develop an efficientmessage passing algorithm that recovers the underlying signal. when the modelparameters defining the underlying graph are unknown, we suggest an algorithmthat learns these parameters directly from the data, leading to an iterativescheme for adaptive sparse signal recovery. the effectiveness of our approachis demonstrated on real-life signals - patches of natural images - where wecompare the denoising performance to that of previous recovery methods that donot exploit the statistical dependencies.
{fenge}
0709.1563	blind multi-band signal reconstruction: compressed sensing for analog  signals	we address the problem of reconstructing a multi-band signal from itssub-nyquist point-wise samples. to date, all reconstruction methods proposedfor this class of signals assumed knowledge of the band locations. in thispaper, we develop a non-linear blind perfect reconstruction scheme formulti-band signals which does not require the band locations. our approachassumes an existing blind multi-coset sampling method. the sparse structure ofmulti-band signals in the continuous frequency domain is used to replace thecontinuous reconstruction with a single finite dimensional problem without theneed for discretization. the resulting problem can be formulated within theframework of compressed sensing, and thus can be solved efficiently using knowntractable algorithms from this emerging area. we also develop a theoreticallower bound on the average sampling rate required for blind signalreconstruction, which is twice the minimal rate of known-spectrum recovery. ourmethod ensures perfect reconstruction for a wide class of signals sampled atthe minimal rate. numerical experiments are presented demonstrating blindsampling and reconstruction with minimal sampling rate.
{fenge}
1103.2469	blind compressed sensing over a structured union of subspaces	this paper addresses the problem of simultaneous signal recovery anddictionary learning based on compressive measurements. multiple signals areanalyzed jointly, with multiple sensing matrices, under the assumption that theunknown signals come from a union of a small number of disjoint subspaces. thisproblem is important, for instance, in image inpainting applications, in whichthe multiple signals are constituted by (incomplete) image patches taken fromthe overall image. this work extends standard dictionary learning andblock-sparse dictionary optimization, by considering compressive measurements,e.g., incomplete data). previous work on blind compressed sensing is alsogeneralized by using multiple sensing matrices and relaxing some of therestrictions on the learned dictionary. drawing on results developed in thecontext of matrix completion, it is proven that both the dictionary and signalscan be recovered with high probability from compressed measurements. thesolution is unique up to block permutations and invertible lineartransformations of the dictionary atoms. the recovery is contingent on thenumber of measurements per signal and the number of signals being sufficientlylarge; bounds are derived for these quantities. in addition, this paperpresents a computationally practical algorithm that performs dictionarylearning and signal recovery, and establishes conditions for its convergence toa local optimum. experimental results for image inpainting demonstrate thecapabilities of the method.
{fenge}
1103.5479	unicity conditions for low-rank matrix recovery	low-rank matrix recovery addresses the problem of recovering an unknownlow-rank matrix from few linear measurements. nuclear-norm minimization is atractible approach with a recent surge of strong theoretical backing. analagousto the theory of compressed sensing, these results have required randommeasurements. for example, m &gt;= cnr gaussian measurements are sufficient torecover any rank-r n x n matrix with high probability. in this paper we addressthe theoretical question of how many measurements are needed via any methodwhatsoever --- tractible or not. we show that for a family of randommeasurement ensembles, m &gt;= 4nr - 4r^2 measurements are sufficient to guaranteethat no rank-2r matrix lies in the null space of the measurement operator withprobability one. this is a necessary and sufficient condition to ensure uniformrecovery of all rank-r matrices by rank minimization. furthermore, this valueof $m$ precisely matches the dimension of the manifold of all rank-2r matrices.we also prove that for a fixed rank-r matrix, m &gt;= 2nr - r^2 + 1 randommeasurements are enough to guarantee recovery using rank minimization. theseresults give a benchmark to which we may compare the efficacy of nuclear-normminimization.
{fenge}
1103.5639	partially linear estimation with application to sparse signal recovery  from measurement pairs	we address the problem of estimating a random vector x from two sets ofmeasurements y and z, such that the estimator is linear in y. we show that thepartially linear minimum mean squared error (plmmse) estimator does not requireknowing the joint distribution of x and y in full, but rather only itssecond-order moments. this renders it of potential interest in variousapplications. we further show that the plmmse method is minimax-optimal amongall estimators that solely depend on the second-order statistics of x and y. wedemonstrate our approach in the context of recovering a signal, which is sparsein a unitary dictionary, from noisy observations of it and of a filteredversion of it. we show that in this setting plmmse estimation has a clearcomputational advantage, while its performance is comparable tostate-of-the-art algorithms. we apply our approach both in static and dynamicestimation applications. in the former category, we treat the problem of imageenhancement from blurred/noisy image pairs, where we show that plmmseestimation performs only slightly worse than state-of-the art algorithms, whilerunning an order of magnitude faster. in the dynamic setting, we provide arecursive implementation of the estimator and demonstrate its utility in thecontext of tracking maneuvering targets from position and accelerationmeasurements.
{fenge}
1105.3326	xampling at the rate of innovation	we address the problem of recovering signals from samples taken at their rateof innovation. our only assumption is that the sampling system is such that theparameters defining the signal can be stably determined from the samples, acondition that lies at the heart of every sampling theorem. consequently, ouranalysis subsumes previously studied nonlinear acquisition devices andnonlinear signal classes. in particular, we do not restrict attention tomemoryless nonlinear distortions or to union-of-subspace models. this allowstreatment of various finite-rate-of-innovation (fri) signals that were notpreviously studied, including, for example, continuous phase modulationtransmissions. our strategy relies on minimizing the error between the measuredsamples and those corresponding to our signal estimate. this least-squares (ls)objective is generally non-convex and might possess many local minima.nevertheless, we prove that under the stability hypothesis, any optimizationmethod designed to trap a stationary point of the ls criterion necessarilyconverges to the true solution. we demonstrate our approach in the context ofrecovering pulse streams in settings that were not previously treated.furthermore, in situations for which other algorithms are applicable, we showthat our method is often preferable in terms of noise robustness.
{fenge}
1106.4514	sub-nyquist sampling: bridging theory and practice	sampling theory encompasses all aspects related to the conversion ofcontinuous-time signals to discrete streams of numbers. the famousshannon-nyquist theorem has become a landmark in the development of digitalsignal processing. in modern applications, an increasingly number of functionsis being pushed forward to sophisticated software algorithms, leaving onlythose delicate finely-tuned tasks for the circuit level.  in this paper, we review sampling strategies which target reduction of theadc rate below nyquist. our survey covers classic works from the early 50's ofthe previous century through recent publications from the past several years.the prime focus is bridging theory and practice, that is to pinpoint thepotential of sub-nyquist strategies to emerge from the math to the hardware. inthat spirit, we integrate contemporary theoretical viewpoints, which studysignal modeling in a union of subspaces, together with a taste of practicalaspects, namely how the avant-garde modalities boil down to concrete signalprocessing systems. our hope is that this presentation style will attract theinterest of both researchers and engineers in the hope of promoting thesub-nyquist premise into practical applications, and encouraging furtherresearch into this exciting new frontier.
{fenge}
1106.6224	structured compressed sensing: from theory to applications	compressed sensing (cs) is an emerging field that has attracted considerableresearch interest over the past few years. previous review articles in cs limittheir scope to standard discrete-to-discrete measurement architectures usingmatrices of randomized nature and signal models based on standard sparsity. inrecent years, cs has worked its way into several new application areas. this,in turn, necessitates a fresh look on many of the basics of cs. the randommatrix measurement operator must be replaced by more structured sensingarchitectures that correspond to the characteristics of feasible acquisitionhardware. the standard sparsity prior has to be extended to include a muchricher class of signals and to encode broader data models, includingcontinuous-time signals. in our overview, the theme is exploiting signal andmeasurement structure in compressive sensing. the prime focus is bridgingtheory and practice; that is, to pinpoint the potential of structured csstrategies to emerge from the math to the hardware. our summary highlights newdirections as well as relations to more traditional cs, with the hope ofserving both as a review to practitioners wanting to join this emerging field,and as a reference for researchers that attempts to put some of the existingideas in perspective of practical applications.
{fenge}
1107.3636	gps signal acquisition via compressive multichannel sampling	in this paper, we propose an efficient acquisition scheme for gps receivers.it is shown that gps signals can be effectively sampled and detected using abank of randomized correlators with much fewer chip-matched filters than thoseused in existing gps signal acquisition algorithms. the latter use correlationswith all possible shifted replicas of the satellite-specific c/a code and anexhaustive search for peaking signals over the delay-doppler space. our schemeis based on the recently proposed analog compressed sensing framework, andconsists of a multichannel sampling structure with far fewer correlators.  the compressive multichannel sampler outputs are linear combinations of avector whose support tends to be sparse; by detecting its support one canidentify the strongest satellite signals in the field of view and pinpoint thecorrect code-phase and doppler shifts for finer resolution during tracking. theanalysis in this paper demonstrates that gps signals can be detected andacquired via the proposed structure at a lower cost in terms of number ofcorrelations that need to be computed in the coarse acquisition phase, which incurrent gps technology scales like the product of the number of all possibledelays and doppler shifts. in contrast, the required number of correlators inour compressive multichannel scheme scales as the number of satellites in thefield of view of the device times the logarithm of number of delay-doppler binsexplored, as is typical for compressed sensing methods.
{fenge}
1109.5415	shannon meets nyquist: capacity of sampled gaussian channels	we explore two fundamental questions at the intersection of sampling theoryand information theory: how channel capacity is affected by sampling below thechannel's nyquist rate, and what sub-nyquist sampling strategy should beemployed to maximize capacity. in particular, we derive the capacity of sampledanalog channels for three prevalent sampling strategies: sampling withfiltering, sampling with filter banks, and sampling with modulation and filterbanks. these sampling mechanisms subsume most nonuniform sampling techniquesapplied in practice. our analyses illuminate interesting connections betweenunder-sampled channels and multiple-input multiple-output channels. the optimalsampling structures are shown to extract out the frequencies with the highestsnr from each aliased frequency set, while suppressing aliasing and out-of-bandnoise. we also highlight connections between undersampled channel capacity andminimum mean-squared error (mse) estimation from sampled data. in particular,we show that the filters maximizing capacity and the ones minimizing mse areequivalent under both filtering and filter-bank sampling strategies. theseresults demonstrate the effect upon channel capacity of sub-nyquist samplingtechniques, and characterize the tradeoff between information rate and samplingrate.
{fenge}
1109.6303	reduced-dimension multiuser detection	we present a reduced-dimension multiuser detector (rd-mud) structure forsynchronous systems that significantly decreases the number of requiredcorrelation branches at the receiver front-end, while still achievingperformance similar to that of the conventional matched-filter (mf) bank.rd-mud exploits the fact that, in some wireless systems, the number of activeusers may be small relative to the total number of users in the system. hence,the ideas of analog compressed sensing may be used to reduce the number ofcorrelators. the correlating signals used by each correlator are chosen as anappropriate linear combination of the users' spreading waveforms. we derive theprobability-of-symbol-error when using two methods for recovery of active usersand their transmitted symbols: the reduced-dimension decorrelating (rdd)detector, which combines subspace projection and thresholding to determineactive users and sign detection for data recovery, and the reduced-dimensiondecision-feedback (rddf) detector, which combines decision-feedback matchingpursuit for active user detection and sign detection for data recovery. wederive probability of error bounds for both detectors, and show that the numberof correlators needed to achieve a small probability-of-symbol-error is on theorder of the logarithm of the number of users in the system. the theoreticalperformance results are validated via numerical simulations.
{fenge}
1201.1200	compressed beamforming applied to b-mode ultrasound imaging	emerging sonography techniques often imply increasing in the number oftransducer elements involved in the imaging process. consequently, largeramounts of data must be acquired and processed by the beamformer. thesignificant growth in the amounts of data effects both machinery size and powerconsumption. within the classical sampling framework, state of the art systemsreduce processing rates by exploiting the bandpass bandwidth of the detectedsignals. it has been recently shown, that a much more significant sample-ratereduction may be obtained, by treating ultrasound signals within the finiterate of innovation framework. these ideas follow the spirit of xampling, whichcombines classic methods from sampling theory with recent developments incompressed sensing. applying such low-rate sampling schemes to individualtransducer elements, which detect energy reflected from biological tissues, islimited by the noisy nature of the signals. this often results in erroneousparameter extraction, bringing forward the need to enhance the snr of thelow-rate samples. in our work, we manage to achieve such snr enhancement, bybeamforming the sub-nyquist samples obtained from multiple elements. we referto this process as "compressed beamforming". applying it to cardiac ultrasounddata, we successfully image macroscopic perturbations, while achieving a nearlyeight-fold reduction in sample-rate, compared to standard techniques.
{fenge}
1202.6037	compressed beamforming in ultrasound imaging	emerging sonography techniques often require increasing the number oftransducer elements involved in the imaging process. consequently, largeramounts of data must be acquired and processed. the significant growth in theamounts of data affects both machinery size and power consumption. within theclassical sampling framework, state of the art systems reduce processing ratesby exploiting the bandpass bandwidth of the detected signals. it has beenrecently shown, that a much more significant sample-rate reduction may beobtained, by treating ultrasound signals within the finite rate of innovationframework. these ideas follow the spirit of xampling, which combines classicmethods from sampling theory with recent developments in compressed sensing.applying such low-rate sampling schemes to individual transducer elements,which detect energy reflected from biological tissues, is limited by the noisynature of the signals. this often results in erroneous parameter extraction,bringing forward the need to enhance the snr of the low-rate samples. in ourwork, we achieve snr enhancement, by beamforming the sub-nyquist samplesobtained from multiple elements. we refer to this process as "compressedbeamforming". applying it to cardiac ultrasound data, we successfully imagemacroscopic perturbations, while achieving a nearly eight-fold reduction insample-rate, compared to standard techniques.
{fenge}
1204.6049	channel capacity under sub-nyquist nonuniform sampling	this paper investigates the effect of sub-nyquist sampling upon the capacityof an analog channel. the channel is assumed to be a linear time-invariantgaussian channel, where perfect channel knowledge is available at both thetransmitter and the receiver. we consider a general class of right-invertibletime-preserving sampling methods which include irregular nonuniform sampling,and characterize in closed form the channel capacity achievable by this classof sampling methods, under a sampling rate and power constraint. our resultsindicate that the optimal sampling structures extract out the set offrequencies that exhibits the highest signal-to-noise ratio among all spectralsets of measure equal to the sampling rate. this can be attained throughfilterbank sampling with uniform sampling at each branch with possiblydifferent rates, or through a single branch of modulation and filteringfollowed by uniform sampling. these results reveal that for a large class ofchannels, employing irregular nonuniform sampling sets, while typicallycomplicated to realize, does not provide capacity gain over uniform samplingsets with appropriate preprocessing. our findings demonstrate that aliasing orscrambling of spectral components does not provide capacity gain, which is incontrast to the benefits obtained from random mixing in spectrum-blindcompressive sampling schemes.
{fenge}
1207.6353	petrels: parallel subspace estimation and tracking by recursive least  squares from partial observations	many real world data sets exhibit an embedding of low-dimensional structurein a high-dimensional manifold. examples include images, videos and internettraffic data. it is of great significance to reduce the storage requirementsand computational complexity when the data dimension is high. therefore weconsider the problem of reconstructing a data stream from a small subset of itsentries, where the data is assumed to lie in a low-dimensional linear subspace,possibly corrupted by noise. we further consider tracking the change of theunderlying subspace, which can be applied to applications such as videodenoising, network monitoring and anomaly detection. our problem can be viewedas a sequential low-rank matrix completion problem in which the subspace islearned in an on-line fashion. the proposed algorithm, dubbed parallelestimation and tracking by recursive least squares (petrels), first identifiesthe underlying low-dimensional subspace via a recursive procedure for each rowof the subspace matrix in parallel with discounting for previous observations,and then reconstructs the missing entries via least-squares estimation ifrequired. numerical examples are provided for direction-of-arrival estimationand matrix completion, comparing petrels with state of the art batchalgorithms.
{fenge}
1208.2515	a sub-nyquist radar prototype: hardware and algorithms	traditional radar sensing typically involves matched filtering between thereceived signal and the shape of the transmitted pulse. under the confinementof classic sampling theorem this requires that the received signals must firstbe sampled at twice the baseband bandwidth, in order to avoid aliasing. thegrowing demands for target distinction capability and spatial resolution implysignificant growth in the bandwidth of the transmitted pulse. thus, correlationbased radar systems require high sampling rates, and with the large amounts ofdata sampled also necessitate vast memory capacity. in addition, real-timeprocessing of the data typically results in high power consumption. recently,new approaches for radar sensing and detection were introduced, based on thefinite rate of innovation and xampling frameworks. these techniques allowsignificant reduction in sampling rate, implying potential power savings, whilemaintaining the system's detection capabilities at high enough snr. here wepresent for the first time a design and implementation of a xampling-basedhardware prototype that allows sampling of radar signals at rates much lowerthan nyquist. we demostrate by real-time analog experiments that our system isable to maintain reasonable detection capabilities, while sampling radarsignals that require sampling at a rate of about 30mhz at a total rate of 1mhz.
{fenge}
1209.3804	compressive link acquisition in multiuser communications	an important receiver operation is to detect the presence specific preamblesignals with unknown delays in the presence of scattering, doppler effects andcarrier offsets. this task, referred to as "link acquisition", is typically asequential search over the transmitted signal space. recently, many authorshave suggested applying sparse recovery algorithms in the context of similarestimation or detection problems. these works typically focus on the benefitsof sparse recovery, but not generally on the cost brought by compressivesensing. thus, our goal is to examine the trade-off in complexity andperformance that is possible when using sparse recovery. to do so, we propose asequential sparsity-aware compressive sampling (c-sa) acquisition scheme, wherea compressive multi-channel sampling (cms) front-end is followed by a sparsityregularized likelihood ratio test (sr-lrt) module.  the proposed c-sa acquisition scheme borrows insights from the models studiedin the context of sub-nyquist sampling, where a minimal amount of samples iscaptured to reconstruct signals with finite rate of innovation (fri). inparticular, we propose an a/d conversion front-end that maximizes a well-knownprobability divergence measure, the average kullback-leibler distance, of allthe hypotheses of the sr-lrt performed on the samples. we compare the proposedacquisition scheme vis-\`{a}-vis conventional alternatives with relatively lowcomputational cost, such as the matched filter (mf), in terms of performanceand complexity.
{fenge}
1211.0722	sub-nyquist radar via doppler focusing	we investigate the problem of a monostatic pulse-doppler radar transceivertrying to detect targets, sparsely populated in the radar's unambiguoustime-frequency region. several past works employ compressed sensing (cs)algorithms to this type of problem, but either do not address sample ratereduction, impose constraints on the radar transmitter, propose cs recoverymethods with prohibitive dictionary size, or perform poorly in noisyconditions. here we describe a sub-nyquist sampling and recovery approachcalled doppler focusing which addresses all of these problems: it performs lowrate sampling and digital processing, imposes no restrictions on thetransmitter, and uses a cs dictionary with size which does not increase withincreasing number of pulses p. furthermore, in the presence of noise, dopplerfocusing enjoys an snr increase which scales linearly with p, obtaining gooddetection performance even at snrs as low as -25db. the recovery is based onthe xampling framework, which allows reducing the number of samples needed toaccurately represent the signal, directly in the analog-to-digital conversionprocess. after sampling, the entire digital recovery process is performed onthe low rate samples without having to return to the nyquist rate. finally, ourapproach can be implemented in hardware using a previously suggested xamplingprototype.
{fenge}
1211.0872	phase retrieval: stability and recovery guarantees	we consider stability and uniqueness in real phase retrieval problems overgeneral input sets. specifically, we assume the data consists of noisyquadratic measurements of an unknown input x in r^n that lies in a general sett and study conditions under which x can be stably recovered from themeasurements. in the noise-free setting we derive a general expression on thenumber of measurements needed to ensure that a unique solution can be found ina stable way, that depends on the set t through a natural complexity parameter.this parameter can be computed explicitly for many sets t of interest. forexample, for k-sparse inputs we show that o(k\log(n/k)) measurements areneeded, and when x can be any vector in r^n, o(n) measurements suffice. in thenoisy case, we show that if one can find a value for which the empirical riskis bounded by a given, computable constant (that depends on the set t), thenthe error with respect to the true input is bounded above by an another,closely related complexity parameter of the set. by choosing an appropriatenumber n of measurements, this bound can be made arbitrarily small, and itdecays at a rate faster than n^{-1/2+\delta} for any \delta&gt;0. in particular,for k-sparse vectors stable recovery is possible from o(k\log(n/k)\log k) noisymeasurements, and when x can be any vector in r^n, o(n \log n) noisymeasurements suffice. we also show that the complexity parameter for thequadratic problem is the same as the one used for analyzing stability in linearmeasurements under very general conditions. thus, no substantial price has tobe paid in terms of stability if there is no knowledge of the phase.
{fenge}
1212.3753	simultaneously structured models with application to sparse and low-rank  matrices	the topic of recovery of a structured model given a small number of linearobservations has been well-studied in recent years. examples include recoveringsparse or group-sparse vectors, low-rank matrices, and the sum of sparse andlow-rank matrices, among others. in various applications in signal processingand machine learning, the model of interest is known to be structured inseveral ways at the same time, for example, a matrix that is simultaneouslysparse and low-rank.  often norms that promote each individual structure are known, and allow forrecovery using an order-wise optimal number of measurements (e.g., $\ell_1$norm for sparsity, nuclear norm for matrix rank). hence, it is reasonable tominimize a combination of such norms. we show that, surprisingly, if we usemulti-objective optimization with these norms, then we can do no better,order-wise, than an algorithm that exploits only one of the present structures.this result suggests that to fully exploit the multiple structures, we need anentirely new convex relaxation, i.e. not one that is a function of the convexrelaxations used for each structure. we then specialize our results to the caseof sparse and low-rank matrices. we show that a nonconvex formulation of theproblem can recover the model from very few measurements, which is on the orderof the degrees of freedom of the matrix, whereas the convex problem obtainedfrom a combination of the $\ell_1$ and nuclear norms requires many moremeasurements. this proves an order-wise gap between the performance of theconvex and nonconvex recovery problems in this case. our framework applies toarbitrary structure-inducing norms as well as to a wide range of measurementensembles. this allows us to give performance bounds for problems such assparse phase retrieval and low-rank tensor completion.
{fenge}
1304.3886	minimum variance estimation of a sparse vector within the linear  gaussian model: an rkhs approach	we consider minimum variance estimation within the sparse linear gaussianmodel (slgm). a sparse vector is to be estimated from a linearly transformedversion embedded in gaussian noise. our analysis is based on the theory ofreproducing kernel hilbert spaces (rkhs). after a characterization of the rkhsassociated with the slgm, we derive novel lower bounds on the minimum varianceachievable by estimators with a prescribed bias function. this includes theimportant case of unbiased estimation. the variance bounds are obtained via anorthogonal projection of the prescribed mean function onto a subspace of therkhs associated with the slgm. furthermore, we specialize our bounds tocompressed sensing measurement matrices and express them in terms of therestricted isometry and coherence parameters. for the special case of the slgmgiven by the sparse signal in noise model (ssnm), we derive closed-formexpressions of the minimum achievable variance (barankin bound) and thecorresponding locally minimum variance estimator. we also analyze the effectsof exact and approximate sparsity information and show that the minimumachievable variance for exact sparsity is not a limiting case of that forapproximate sparsity. finally, we compare our bounds with the variance of threewell-known estimators, namely, the maximum-likelihood estimator, thehard-thresholding estimator, and compressive reconstruction using theorthogonal matching pursuit.
{fenge}
1304.4578	spatial compressive sensing for mimo radar	we study compressive sensing in the spatial domain to achieve targetlocalization, specifically direction of arrival (doa), using multiple-inputmultiple-output (mimo) radar. a sparse localization framework is proposed for amimo array in which transmit and receive elements are placed at random. thisallows for a dramatic reduction in the number of elements needed, while stillattaining performance comparable to that of a filled (nyquist) array. byleveraging properties of structured random matrices, we develop a bound on thecoherence of the resulting measurement matrix, and obtain conditions underwhich the measurement matrix satisfies the so-called isotropy property. thecoherence and isotropy concepts are used to establish uniform and non-uniformrecovery guarantees within the proposed spatial compressive sensing framework.in particular, we show that non-uniform recovery is guaranteed if the productof the number of transmit and receive elements, mn (which is also the number ofdegrees of freedom), scales with k(log(g))^2, where k is the number of targetsand g is proportional to the array aperture and determines the angleresolution. in contrast with a filled virtual mimo array where the product mnscales linearly with g, the logarithmic dependence on g in the proposedframework supports the high-resolution provided by the virtual array aperturewhile using a small number of mimo radar elements. in the numerical results weshow that, in the proposed framework, compressive sensing recovery algorithmsare capable of better performance than classical methods, such as beamformingand music.
{fenge}
1304.6281	subspace recovery from structured union of subspaces	lower dimensional signal representation schemes frequently assume that thesignal of interest lies in a single vector space. in the context of therecently developed theory of compressive sensing (cs), it is often assumed thatthe signal of interest is sparse in an orthonormal basis. however, in manypractical applications, this requirement may be too restrictive. ageneralization of the standard sparsity assumption is that the signal lies in aunion of subspaces. recovery of such signals from a small number of samples hasbeen studied recently in several works. here, we consider the problem ofsubspace recovery in which our goal is to identify the subspace (from theunion) in which the signal lies using a small number of samples, in thepresence of noise. more specifically, we derive performance bounds andconditions under which reliable subspace recovery is guaranteed using maximumlikelihood (ml) estimation. we begin by treating general unions and then obtainthe results for the special case in which the subspaces have structure leadingto block sparsity. in our analysis, we treat both general sampling operatorsand random sampling matrices. with general unions, we show that under certainconditions, the number of measurements required for reliable subspace recoveryin the presence of noise via ml is less than that implied using the restrictedisometry property which guarantees signal recovery. in the special case ofblock sparse signals, we quantify the gain achievable over standard sparsity insubspace recovery. our results also strengthen existing results on sparsesupport recovery in the presence of noise under the standard sparsity model.
{fenge}
1304.7751	minimax capacity loss under sub-nyquist universal sampling	this paper investigates the information rate loss in analog channels when thesampler is designed to operate independent of the instantaneous channeloccupancy. specifically, a multiband linear time-invariant gaussian channelunder universal sub-nyquist sampling is considered. the entire channelbandwidth is divided into $n$ subbands of equal bandwidth. at each time only$k$ constant-gain subbands are active, where the instantaneous subbandoccupancy is not known at the receiver and the sampler. we study theinformation loss through a capacity loss metric, that is, the capacity gapcaused by the lack of instantaneous subband occupancy information. wecharacterize the minimax capacity loss for the entire sub-nyquist rate regime,provided that the number $n$ of subbands and the snr are both large. theminimax limits depend almost solely on the band sparsity factor and theundersampling factor, modulo some residual terms that vanish as $n$ and snrgrow. our results highlight the power of randomized sampling methods (i.e. thesamplers that consist of random periodic modulation and low-pass filters),which are able to approach the minimax capacity loss with exponentially highprobability.
{fenge}
1307.6345	fourier domain beamforming: the path to compressed ultrasound imaging	sonography techniques use multiple transducer elements for tissuevisualization. signals detected at each element are sampled prior to digitalbeamforming. the sampling rates required to perform high resolution digitalbeamforming are significantly higher than the nyquist rate of the signal andresult in considerable amount of data, that needs to be stored and processed. arecently developed technique, compressed beamforming, based on the finite rateof innovation model, compressed sensing (cs) and xampling ideas, allows toreduce the number of samples needed to reconstruct an image comprised of strongreflectors. a drawback of this method is its inability to treat speckle, whichis of significant importance in medical imaging. here we build on previous workand extend it to a general concept of beamforming in frequency. this allows toexploit the low bandwidth of the ultrasound signal and bypass the oversamplingdictated by digital implementation of beamforming in time. using beamforming infrequency, the same image quality is obtained from far fewer samples. we nextpresent a cs-technique that allows for further rate reduction, using only aportion of the beamformed signal's bandwidth. we demonstrate our methods on invivo cardiac data and show that reductions up to 1/28 over standard beamformingrates are possible. finally, we present an implementation on an ultrasoundmachine using sub-nyquist sampling and processing. our results prove that theconcept of sub-nyquist processing is feasible for medical ultrasound, leadingto the potential of considerable reduction in future ultrasound machines size,power consumption and cost.
{fenge}
1308.5000	smoothing and decomposition for analysis sparse recovery	we consider algorithms and recovery guarantees for the analysis sparse modelin which the signal is sparse with respect to a highly coherent frame. weconsider the use of a monotone version of the fast iterative shrinkage-thresholding algorithm (mfista) to solve the analysis sparse recovery problem.since the proximal operator in mfista does not have a closed-form solution forthe analysis model, it cannot be applied directly. instead, we examine twoalternatives based on smoothing and decomposition transformations that relaxthe original sparse recovery problem, and then implement mfista on the relaxedformulation. we refer to these two methods as smoothing-based anddecomposition-based mfista. we analyze the convergence of both algorithms, andestablish that smoothing- based mfista converges more rapidly when applied togeneral nonsmooth optimization problems. we then derive a performance bound onthe reconstruction error using these techniques. the bound proves that ourmethods can recover a signal sparse in a redundant tight frame when themeasurement matrix satisfies a properly adapted restricted isometry property.numerical examples demonstrate the performance of our methods and show thatsmoothing-based mfista converges faster than the decomposition-basedalternative in real applications, such as mri image reconstruction.
{fenge}
1308.5149	sub-nyquist sampling for power spectrum sensing in cognitive radios: a  unified approach	in light of the ever-increasing demand for new spectral bands and theunderutilization of those already allocated, the concept of cognitive radio(cr) has emerged. opportunistic users could exploit temporarily vacant bandsafter detecting the absence of activity of their owners. one of the crucialtasks in the cr cycle is therefore spectrum sensing and detection which has tobe precise and efficient. yet, crs typically deal with wideband signals whosenyquist rates are very high. in this paper, we propose to reconstruct the powerspectrum of such signals from sub-nyquist samples, rather than the signalitself as done in previous work, in order to perform detection. we considerboth sparse and non sparse signals as well as blind and non blind detection inthe sparse case. for each one of those scenarii, we derive the minimal samplingrate allowing perfect reconstruction of the signal's power spectrum in anoise-free environment and provide power spectrum recovery techniques thatachieve those rates. the analysis is performed for two different signal modelsconsidered in the literature, which we refer to as the analog and digitalmodels, and shows that both lead to similar results. simulations demonstratepower spectrum recovery at the minimal rate in noise-free settings and show theimpact of several parameters on the detector performance, includingsignal-to-noise ratio (snr), sensing time and sampling rate.
{fenge}
1308.6086	distributed compressed sensing for static and time-varying networks	we consider the problem of in-network compressed sensing from distributedmeasurements. every agent has a set of measurements of a signal $x$, and theobjective is for the agents to recover $x$ from their collective measurementsusing only communication with neighbors in the network. our distributedapproach to this problem is based on the centralized iterative hardthresholding algorithm (iht). we first present a distributed iht algorithm forstatic networks that leverages standard tools from distributed computing toexecute in-network computations with minimized bandwidth consumption. next, weaddress distributed signal recovery in networks with time-varying topologies.the network dynamics necessarily introduce inaccuracies to our in-networkcomputations. to accommodate these inaccuracies, we show how centralized ihtcan be extended to include inexact computations while still providing the samerecovery guarantees as the original iht algorithm. we then leverage these newtheoretical results to develop a distributed version of iht for time-varyingnetworks. evaluations show that our distributed algorithms for both static andtime-varying networks outperform previously proposed solutions in time andbandwidth by several orders of magnitude.
{fenge}
1311.2448	recovery of sparse matrices via matrix sketching	in this paper, we consider the problem of recovering an unknown sparse matrixx from the matrix sketch y = ax b^t. the dimension of y is less than that of x,and a and b are known matrices. this problem can be solved using standardcompressive sensing (cs) theory after converting it to vector form using thekronecker operation. in this case, the measurement matrix assumes a kroneckerproduct structure. however, as the matrix dimension increases the associatedcomputational complexity makes its use prohibitive. we extend two algorithms,fast iterative shrinkage threshold algorithm (fista) and orthogonal matchingpursuit (omp) to solve this problem in matrix form without employing thekronecker product. while both fista and omp with matrix inputs are shown to beequivalent in performance to their vector counterparts with the kroneckerproduct, solving them in matrix form is shown to be computationally moreefficient. we show that the computational gain achieved by fista with matrixinputs over its vector form is more significant compared to that achieved byomp.
{fenge}
1312.2574	backing off from infinity: performance bounds via concentration of  spectral measure for random mimo channels	the performance analysis of random vector channels, particularlymultiple-input-multiple-output (mimo) channels, has largely been established inthe asymptotic regime of large channel dimensions, due to the analyticalintractability of characterizing the exact distribution of the objectiveperformance metrics. this paper exposes a new non-asymptotic framework thatallows the characterization of many canonical mimo system performance metricsto within a narrow interval under moderate-to-large channel dimensionality,provided that these metrics can be expressed as a separable function of thesingular values of the matrix. the effectiveness of our framework isillustrated through two canonical examples. specifically, we characterize themutual information and power offset of random mimo channels, as well as theminimum mean squared estimation error of mimo channel inputs from the channeloutputs. our results lead to simple, informative, and reasonably accuratecontrol of various performance metrics in the finite-dimensional regime, ascorroborated by the numerical simulations. our analysis framework isestablished via the concentration of spectral measure phenomenon for randommatrices uncovered by guionnet and zeitouni, which arises in a variety ofrandom matrix ensembles irrespective of the precise distributions of the matrixentries.
{fenge}
0802.1311	reduce and boost: recovering arbitrary sets of jointly sparse vectors	the rapid developing area of compressed sensing suggests that a sparse vectorlying in an arbitrary high dimensional space can be accurately recovered fromonly a small set of non-adaptive linear measurements. under appropriateconditions on the measurement matrix, the entire information about the originalsparse vector is captured in the measurements, and can be recovered usingefficient polynomial methods. the vector model has been extended to a finiteset of sparse vectors sharing a common non-zero location set. in this paper, wetreat a broader framework in which the goal is to recover a possibly infiniteset of jointly sparse vectors. extending existing recovery methods to thismodel is difficult due to the infinite structure of the sparse vector set.instead, we prove that the entire infinite set of sparse vectors can recoveredby solving a single, reduced-size finite-dimensional problem, corresponding torecovery of a finite set of sparse vectors. we then show that the problem canbe further reduced to the basic recovery of a single sparse vector by randomlycombining the measurement vectors. our approach results in exact recovery ofboth countable and uncountable sets as it does not rely on discretization orheuristic techniques. to efficiently recover the single sparse vector producedby the last reduction step, we suggest an empirical boosting strategy thatimproves the recovery ability of any given sub-optimal method for recovering asparse vector. numerical experiments on random data demonstrate that whenapplied to infinite sets our strategy outperforms discretization techniques interms of both run time and empirical recovery rate. in the finite model, ourboosting algorithm is characterized by fast run time and superior recovery ratethan known popular methods.
{fenge}
1312.7793	direction of arrival estimation using co-prime arrays: a super  resolution viewpoint	we consider the problem of direction of arrival (doa) estimation using anewly proposed structure of non-uniform linear arrays, referred to as co-primearrays, in this paper. by exploiting the second order statistical informationof the received signals, co-prime arrays exhibit o(mn) degrees of freedom withonly m + n sensors. a sparsity based recovery method is proposed to fullyutilize these degrees of freedom. unlike traditional sparse recovery methods,the proposed method is based on the developing theory of super resolution,which considers a continuous range of possible sources instead of discretizingthis range into a discrete grid. with this approach, off-grid effects inheritedin traditional sparse recovery can be neglected, thus improving the accuracy ofdoa estimation. in this paper we show that in the noiseless case one cantheoretically detect up to m n sources with only 2m + n sensors. the noise 2statistics of co-prime arrays are also analyzed to demonstrate the robustnessof the proposed optimization scheme. a source number detection method ispresented based on the spectrum reconstructed from the sparse method. byextensive numerical examples, we show the superiority of the proposed method interms of doa estimation accuracy, degrees of freedom, and resolution abilitycompared with previous methods, such as music with spatial smoothing and thediscrete sparse recovery method.
{fenge}
1405.5329	distortion-rate function of sub-nyquist sampled gaussian sources	the amount of information lost in sub-nyquist sampling of a continuous-timegaussian stationary process is quantified. we consider a combined source codingand sub-nyquist reconstruction problem in which the input to the encoder is anoisy sub-nyquist sampled version of the analog source. we first derive anexpression for the mean squared error in the reconstruction of the process froma noisy and information rate-limited version of its samples. this expression isa function of the sampling frequency and the average number of bits describingeach sample. it is given as the sum of two terms: minimum mean square error inestimating the source from its noisy but otherwise fully observed sub-nyquistsamples, and a second term obtained by reverse waterfilling over an average ofspectral densities associated with the polyphase components of the source. weextend this result to multi-branch uniform sampling, where the samples areavailable through a set of parallel channels with a uniform sampler and apre-sampling filter in each branch. further optimization to reduce distortionis then performed over the pre-sampling filters, and an optimal set ofpre-sampling filters associated with the statistics of the input signal and thesampling frequency is found. this results in an expression for the minimalpossible distortion achievable under any analog to digital conversion schemeinvolving uniform sampling and linear filtering. these results thus unify theshannon-whittaker-kotelnikov sampling theorem and shannon rate-distortiontheory for gaussian sources.
{fenge}
1407.2602	compressed sensing for longitudinal mri: an adaptive-weighted approach	purpose: repeated brain mri scans are performed in many clinical scenarios,such as follow up of patients with tumors and therapy response assessment. inthis paper, the authors show an approach to utilize former scans of the patientfor the acceleration of repeated mri scans.  methods: the proposed approach utilizes the possible similarity of therepeated scans in longitudinal mri studies. since similarity is not guaranteed,sampling and reconstruction are adjusted during acquisition to match the actualsimilarity between the scans. the baseline mr scan is utilized both in thesampling stage, via adaptive sampling, and in the reconstruction stage, withweighted reconstruction. in adaptive sampling, k-space sampling locations areoptimized during acquisition. weighted reconstruction uses the locations of thenonzero coefficients in the sparse domains as a prior in the recovery process.the approach was tested on 2d and 3d mri scans of patients with brain tumors.  results: the longitudinal adaptive cs mri (lacs-mri) scheme providesreconstruction quality which outperforms other cs-based approaches for rapidmri. examples are shown on patients with brain tumors and demonstrate improvedspatial resolution. compared with data sampled at nyquist rate, lacs-mriexhibits signal-to-error ratio (ser) of 24.8db with undersampling factor of16.6 in 3d mri.  conclusions: the authors have presented a novel method for imagereconstruction utilizing similarity of scans in longitudinal mri studies, wherepossible. the proposed approach can play a major part and significantly reducescanning time in many applications that consist of disease follow-up andmonitoring of longitudinal changes in brain mri.
{fenge}
1411.2183	undersampled phase retrieval with outliers	we propose a general framework for reconstructing transform-sparse imagesfrom undersampled (squared)-magnitude data corrupted with outliers. thisframework is implemented using a multi-layered approach, combining multipleinitializations (to address the nonconvexity of the phase retrieval problem),repeated minimization of a convex majorizer (surrogate for a nonconvexobjective function), and iterative optimization using the alternatingdirections method of multipliers. exploiting the generality of this framework,we investigate using a laplace measurement noise model better adapted tooutliers present in the data than the conventional gaussian noise model. usingsimulations, we explore the sensitivity of the method to both theregularization and penalty parameters. we include 1d monte carlo and 2d imagereconstruction comparisons with alternative phase retrieval algorithms. theresults suggest the proposed method, with the laplace noise model, bothincreases the likelihood of correct support recovery and reduces the meansquared error from measurements containing outliers. we also describe excitingextensions made possible by the generality of the proposed framework, includingregularization using analysis-form sparsity priors that are incompatible withmany existing approaches.
{fenge}
1411.2238	structure-based super-resolution recovery of three-photon quantum states  from two-fold coincidences	the field of quantum information has been growing fast over the past decade.optical quantum computation, based on the concepts of klm and cluster states,has witnessed experimental realizations of larger and more complex systems interms of photon number. quantum optical systems, which offer long coherencetimes and easy manipulation of single qubits, allow us to probe quantumproperties of the light itself and of the physical systems around it. recently,a linear scheme for quantum computing, relying on the bosonic nature ofparticles, has been proposed and realized experimentally with photons. theability to efficiently measure superpositions of quantum states consisting ofseveral photons is essential to the characterization of such systems. in fact,the entire field of quantum information completely relies on the ability torecover quantum states from measurements. however, the characterization ofquantum states requires many measurements, and often necessitates complicatedmeasurements schemes; for example, characterizing qubits requires measurements.here, we utilize structure, inherent to physically interesting quantum statesof light, in order to reduce the complexity in the recovery of a quantum state.in particular, we devise a method enabling the recovery of three-photon quantumstates from only two-fold correlation measurements in a single setting. theability to take two-fold coincidences instead of three-fold offers the recoveryof the quantum states in far less measurements and in a considerably highersnr, because detection of two-photon events is much more likely than that ofthree-photon ones. the concept suggested here paves the way to further ideas onstructure-based super resolution in quantum state tomography, such asrecovering a quantum state in an unknown basis in a single setup and recoveringthe state of several photons without number resolving detectors.
{fenge}
0804.3010	generalized sure for exponential families: applications to  regularization	stein's unbiased risk estimate (sure) was proposed by stein for theindependent, identically distributed (iid) gaussian model in order to deriveestimates that dominate least-squares (ls). in recent years, the sure criterionhas been employed in a variety of denoising problems for choosingregularization parameters that minimize an estimate of the mean-squared error(mse). however, its use has been limited to the iid case which precludes manyimportant applications. in this paper we begin by deriving a sure counterpartfor general, not necessarily iid distributions from the exponential family.this enables extending the sure design technique to a much broader class ofproblems. based on this generalization we suggest a new method for choosingregularization parameters in penalized ls estimators. we then demonstrate itssuperior performance over the conventional generalized cross validationapproach and the discrepancy method in the context of image deblurring anddeconvolution. the sure technique can also be used to design estimates withoutpredefining their structure. however, allowing for too many free parametersimpairs the performance of the resulting estimates. to address this inherenttradeoff we propose a regularized sure objective. based on this designcriterion, we derive a wavelet denoising strategy that is similar in sprit tothe standard soft-threshold approach but can lead to improved mse performance.
{fenge}
1507.05498	on the minimax risk of dictionary learning	we consider the problem of learning a dictionary matrix from a number ofobserved signals, which are assumed to be generated via a linear model with acommon underlying dictionary. in particular, we derive lower bounds on theminimum achievable worst case mean squared error (mse), regardless ofcomputational complexity of the dictionary learning (dl) schemes. by casting dlas a classical (or frequentist) estimation problem, the lower bounds on theworst case mse are derived by following an established information-theoreticapproach to minimax estimation. the main conceptual contribution of this paperis the adaption of the information-theoretic approach to minimax estimation forthe dl problem in order to derive lower bounds on the worst case mse of any dlscheme. we derive three different lower bounds applying to different generativemodels for the observed signals. the first bound applies to a wide range ofmodels, it only requires the existence of a covariance matrix of the (unknown)underlying coefficient vector. by specializing this bound to the case of sparsecoefficient distributions, and assuming the true dictionary satisfies therestricted isometry property, we obtain a lower bound on the worst case mse ofdl schemes in terms of a signal to noise ratio (snr). the third bound appliesto a more restrictive subclass of coefficient distributions by requiring thenon-zero coefficients to be gaussian. while, compared with the previous twobounds, the applicability of this final bound is the most limited it is thetightest of the three bounds in the low snr regime.
{fenge}
1508.04893	sub-nyquist sampling and fourier domain beamforming in volumetric  ultrasound imaging	one of the key steps in ultrasound image formation is digital beamforming ofsignals sampled by several transducer elements placed upon an array.high-resolution digital beamforming introduces the demand for sampling ratessignificantly higher than the signals' nyquist rate, which greatly increasesthe volume of data that must be transmitted from the system's front end. in 3dultrasound imaging, 2d transducer arrays rather than 1d arrays are used, andmore scan-lines are needed. this implies that the amount of sampled data isvastly increased with respect to 2d imaging. in this work we show that aconsiderable reduction in data rate can be achieved by applying the ideas ofxampling and frequency domain beamforming, leading to a sub-nyquist samplingrate, which uses only a portion of the bandwidth of the ultrasound signals toreconstruct the image. we extend previous work on frequency domain beamformingfor 2d ultrasound imaging to accommodate the geometry imposed by volumetricscanning and a 2d grid of transducer elements. we demonstrate high imagequality from low-rate samples by simulation of a phantom image comprised ofseveral small reflectors. we also apply our technique on raw data of a heartventricle phantom obtained by a commercial 3d ultrasound system. we show thatby performing 3d beamforming in the frequency domain, sub-nyquist sampling andlow processing rate are achievable, while maintaining adequate image quality.
{fenge}
0806.3332	compressed sensing of analog signals in shift-invariant spaces	a traditional assumption underlying most data converters is that the signalshould be sampled at a rate exceeding twice the highest frequency. thisstatement is based on a worst-case scenario in which the signal occupies theentire available bandwidth. in practice, many signals are sparse so that onlypart of the bandwidth is used. in this paper, we develop methods for low-ratesampling of continuous-time sparse signals in shift-invariant (si) spaces,generated by m kernels with period t. we model sparsity by treating the case inwhich only k out of the m generators are active, however, we do not know whichk are chosen. we show how to sample such signals at a rate much lower than m/t,which is the minimal sampling rate without exploiting sparsity. our approachcombines ideas from analog sampling in a subspace with a recently developedblock diagram that converts an infinite set of sparse equations to a finitecounterpart. using these two components we formulate our problem within theframework of finite compressed sensing (cs) and then rely on algorithmsdeveloped in that context. the distinguishing feature of our results is that incontrast to standard cs, which treats finite-length vectors, we considersampling of analog signals for which no underlying finite-dimensional modelexists. the proposed framework allows to extend much of the recent literatureon cs to the analog domain.
{fenge}
0807.4581	robust recovery of signals from a structured union of subspaces	traditional sampling theories consider the problem of reconstructing anunknown signal $x$ from a series of samples. a prevalent assumption which oftenguarantees recovery from the given measurements is that $x$ lies in a knownsubspace. recently, there has been growing interest in nonlinear but structuredsignal models, in which $x$ lies in a union of subspaces. in this paper wedevelop a general framework for robust and efficient recovery of such signalsfrom a given set of samples. more specifically, we treat the case in which $x$lies in a sum of $k$ subspaces, chosen from a larger set of $m$ possibilities.the samples are modelled as inner products with an arbitrary set of samplingfunctions. to derive an efficient and robust recovery algorithm, we show thatour problem can be formulated as that of recovering a block-sparse vector whosenon-zero elements appear in fixed blocks. we then propose a mixed$\ell_2/\ell_1$ program for block sparse recovery. our main result is anequivalence condition under which the proposed convex algorithm is guaranteedto recover the original signal. this result relies on the notion of blockrestricted isometry property (rip), which is a generalization of the standardrip used extensively in the context of compressed sensing. based on rip we alsoprove stability of our approach in the presence of noise and modelling errors.  a special case of our framework is that of recovering multiple measurementvectors (mmv) that share a joint sparsity pattern. adapting our results to thiscontext leads to new mmv recovery methods as well as equivalence conditionsunder which the entire set can be determined efficiently.
{fenge}
0809.3731	uncertainty relations for shift-invariant analog signals	the past several years have witnessed a surge of research investigatingvarious aspects of sparse representations and compressed sensing. most of thiswork has focused on the finite-dimensional setting in which the goal is todecompose a finite-length vector into a given finite dictionary. underlyingmany of these results is the conceptual notion of an uncertainty principle: asignal cannot be sparsely represented in two different bases. here, we extendthese ideas and results to the analog, infinite-dimensional setting byconsidering signals that lie in a finitely-generated shift-invariant (si)space. this class of signals is rich enough to include many interesting specialcases such as multiband signals and splines. by adapting the notion ofcoherence defined for finite dictionaries to infinite si representations, wedevelop an uncertainty principle similar in spirit to its finite counterpart.we demonstrate tightness of our bound by considering a bandlimited lowpasstrain that achieves the uncertainty principle. building upon these results andsimilar work in the finite setting, we show how to find a sparse decompositionin an overcomplete dictionary by solving a convex optimization problem. thedistinguishing feature of our approach is the fact that even though the problemis defined over an infinite domain with infinitely many variables andconstraints, under certain conditions on the dictionary spectrum our algorithmcan find the sparsest representation by solving a finite-dimensional problem.
