{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tf-idf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QhlpLUJfZQi-vHUCjJaAsoaJ1R6cU_RL",
      "authorship_tag": "ABX9TyMtincA30IPtdtKBl6H70MH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oguzhankoc55/Tf-idf/blob/main/Tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j-gm8NTAXQDH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import re\n",
        "from gensim import utils\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listpath_manu= \"/content/drive/MyDrive/NLP/Dataset/manuscripts/0902.1601.txt\"\n",
        "docA = open(listpath_manu, \"r\")\n",
        "docA=docA.read()\n",
        "print(docA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSUCm8LlchqT",
        "outputId": "4a355009-37a4-4fae-c29f-eb3ca1e08683"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "near-horizon geometry and the entropy of a minimally coupled scalar  field in the schwarzschild black hole in this article, we will discuss a lorentzian sector calculation of theentropy of a minimally coupled scalar field in the schwarzschild black holebackground using the brick wall model of 't hooft. in the original article, thewkb approximation was used for the modes that are globally stationary. in aprevious article, we found that the wkb quantization rule together with aproper counting of the states, leads to a new expression of the scalar fieldentropy which is not proportional to the area of the horizon. the expression ofthe entropy is logarithmically divergent in the brick wall cut-off parameter incontrast to an inverse power divergence obtained earlier. in this article, wewill consider the entropy for a thin shell of matter field of a given thicknesssurrounding the black hole horizon. the thickness is chosen to be largecompared with the planck length and is of the order of the atomic scale. whenexpressed in terms of a covariant cut-off parameter, the entropy of a thinshell of matter field of a given thickness and surrounding the horizon in theschwarzschild black hole background is given by an expression proportional tothe area of the black hole horizon. this leading order divergent term in thecut-off parameter remains to be logarithmically divergent. the logarithmicdivergence is expected from the nature of the solution in the near-horizonregion. we will find that these discussions are significant in the context ofthe continuation to the euclidean sector and the corresponding regularizationschemes used to evaluate the thermodynamical properties of matter fields incurved spaces. these are related with the geometric aspects of curved spaces.the above discussions are also important in presence of cosmological eventhorizon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listpath_manu= \"/content/drive/MyDrive/NLP/Dataset/manuscripts/0910.2755.txt\"\n",
        "docB = open(listpath_manu, \"r\")\n",
        "docB=docB.read()\n",
        "print(docB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjGjtgyxc-KW",
        "outputId": "f51abde3-df70-4f43-84dd-b14a11320937"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "black hole entropy predictions without the immirzi parameter and hawking  radiation of a single-partition black hole by pointing out an error in the previous derivation of the area spectrumbased on ashtekar's variables, we suggest a new area spectrum; instead of thenorm of ashtekar's gravitational electric field, we show that the norm of our\"new\" gravitational electric field based on our \"newer\" variables, which weconstruct in this paper for this purpose, gives the correct area spectrum. inparticular, our \"newer\" variables are mathematically consistent; the constraintalgebra is closed. moreover, by using our new area spectrum, we \"almostcorrectly\" predict the bekenstein-hawking entropy without having to adjust theimmirzi parameter; we show that a numerical formula actually yielded$0.997\\cdots$, which is very close to 1, the expected value with the black holeentropy given as $a/4$. we conjecture that the difference, 0.003, is due to theextra dimensions that may modify the area spectrum. then, we derive a formulafor the degeneracy for a single-partition black hole, i.e., a black hole madeof a single unit area, and explicitly show that our area spectrum correctlyreproduces the degeneracy. furthermore, by using two totally different methods,we obtain the proportionality constant \"$c$\" related to the degeneracy. thefirst method based on fitting yields 172$\\sim$173 while the second methodyields 172.87$\\cdots$, which strongly suggest that our area spectrum is on theright track. we also show that the area spectra based on ashtekar variablesneither reproduce the degeneracy of single-partition black hole nor yieldagreement for $c$ obtained by using the two methods.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bowA = docA.split(\" \")\n",
        "bowB = docB.split(\" \")"
      ],
      "metadata": {
        "id": "FQrkvcepdJ7e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bowB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIt0uExhdLY-",
        "outputId": "0a2a91dd-6449-48e3-ea1b-b3889d159f09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['black',\n",
              " 'hole',\n",
              " 'entropy',\n",
              " 'predictions',\n",
              " 'without',\n",
              " 'the',\n",
              " 'immirzi',\n",
              " 'parameter',\n",
              " 'and',\n",
              " 'hawking',\n",
              " '',\n",
              " 'radiation',\n",
              " 'of',\n",
              " 'a',\n",
              " 'single-partition',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'by',\n",
              " 'pointing',\n",
              " 'out',\n",
              " 'an',\n",
              " 'error',\n",
              " 'in',\n",
              " 'the',\n",
              " 'previous',\n",
              " 'derivation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'area',\n",
              " 'spectrumbased',\n",
              " 'on',\n",
              " \"ashtekar's\",\n",
              " 'variables,',\n",
              " 'we',\n",
              " 'suggest',\n",
              " 'a',\n",
              " 'new',\n",
              " 'area',\n",
              " 'spectrum;',\n",
              " 'instead',\n",
              " 'of',\n",
              " 'thenorm',\n",
              " 'of',\n",
              " \"ashtekar's\",\n",
              " 'gravitational',\n",
              " 'electric',\n",
              " 'field,',\n",
              " 'we',\n",
              " 'show',\n",
              " 'that',\n",
              " 'the',\n",
              " 'norm',\n",
              " 'of',\n",
              " 'our\"new\"',\n",
              " 'gravitational',\n",
              " 'electric',\n",
              " 'field',\n",
              " 'based',\n",
              " 'on',\n",
              " 'our',\n",
              " '\"newer\"',\n",
              " 'variables,',\n",
              " 'which',\n",
              " 'weconstruct',\n",
              " 'in',\n",
              " 'this',\n",
              " 'paper',\n",
              " 'for',\n",
              " 'this',\n",
              " 'purpose,',\n",
              " 'gives',\n",
              " 'the',\n",
              " 'correct',\n",
              " 'area',\n",
              " 'spectrum.',\n",
              " 'inparticular,',\n",
              " 'our',\n",
              " '\"newer\"',\n",
              " 'variables',\n",
              " 'are',\n",
              " 'mathematically',\n",
              " 'consistent;',\n",
              " 'the',\n",
              " 'constraintalgebra',\n",
              " 'is',\n",
              " 'closed.',\n",
              " 'moreover,',\n",
              " 'by',\n",
              " 'using',\n",
              " 'our',\n",
              " 'new',\n",
              " 'area',\n",
              " 'spectrum,',\n",
              " 'we',\n",
              " '\"almostcorrectly\"',\n",
              " 'predict',\n",
              " 'the',\n",
              " 'bekenstein-hawking',\n",
              " 'entropy',\n",
              " 'without',\n",
              " 'having',\n",
              " 'to',\n",
              " 'adjust',\n",
              " 'theimmirzi',\n",
              " 'parameter;',\n",
              " 'we',\n",
              " 'show',\n",
              " 'that',\n",
              " 'a',\n",
              " 'numerical',\n",
              " 'formula',\n",
              " 'actually',\n",
              " 'yielded$0.997\\\\cdots$,',\n",
              " 'which',\n",
              " 'is',\n",
              " 'very',\n",
              " 'close',\n",
              " 'to',\n",
              " '1,',\n",
              " 'the',\n",
              " 'expected',\n",
              " 'value',\n",
              " 'with',\n",
              " 'the',\n",
              " 'black',\n",
              " 'holeentropy',\n",
              " 'given',\n",
              " 'as',\n",
              " '$a/4$.',\n",
              " 'we',\n",
              " 'conjecture',\n",
              " 'that',\n",
              " 'the',\n",
              " 'difference,',\n",
              " '0.003,',\n",
              " 'is',\n",
              " 'due',\n",
              " 'to',\n",
              " 'theextra',\n",
              " 'dimensions',\n",
              " 'that',\n",
              " 'may',\n",
              " 'modify',\n",
              " 'the',\n",
              " 'area',\n",
              " 'spectrum.',\n",
              " 'then,',\n",
              " 'we',\n",
              " 'derive',\n",
              " 'a',\n",
              " 'formulafor',\n",
              " 'the',\n",
              " 'degeneracy',\n",
              " 'for',\n",
              " 'a',\n",
              " 'single-partition',\n",
              " 'black',\n",
              " 'hole,',\n",
              " 'i.e.,',\n",
              " 'a',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'madeof',\n",
              " 'a',\n",
              " 'single',\n",
              " 'unit',\n",
              " 'area,',\n",
              " 'and',\n",
              " 'explicitly',\n",
              " 'show',\n",
              " 'that',\n",
              " 'our',\n",
              " 'area',\n",
              " 'spectrum',\n",
              " 'correctlyreproduces',\n",
              " 'the',\n",
              " 'degeneracy.',\n",
              " 'furthermore,',\n",
              " 'by',\n",
              " 'using',\n",
              " 'two',\n",
              " 'totally',\n",
              " 'different',\n",
              " 'methods,we',\n",
              " 'obtain',\n",
              " 'the',\n",
              " 'proportionality',\n",
              " 'constant',\n",
              " '\"$c$\"',\n",
              " 'related',\n",
              " 'to',\n",
              " 'the',\n",
              " 'degeneracy.',\n",
              " 'thefirst',\n",
              " 'method',\n",
              " 'based',\n",
              " 'on',\n",
              " 'fitting',\n",
              " 'yields',\n",
              " '172$\\\\sim$173',\n",
              " 'while',\n",
              " 'the',\n",
              " 'second',\n",
              " 'methodyields',\n",
              " '172.87$\\\\cdots$,',\n",
              " 'which',\n",
              " 'strongly',\n",
              " 'suggest',\n",
              " 'that',\n",
              " 'our',\n",
              " 'area',\n",
              " 'spectrum',\n",
              " 'is',\n",
              " 'on',\n",
              " 'theright',\n",
              " 'track.',\n",
              " 'we',\n",
              " 'also',\n",
              " 'show',\n",
              " 'that',\n",
              " 'the',\n",
              " 'area',\n",
              " 'spectra',\n",
              " 'based',\n",
              " 'on',\n",
              " 'ashtekar',\n",
              " 'variablesneither',\n",
              " 'reproduce',\n",
              " 'the',\n",
              " 'degeneracy',\n",
              " 'of',\n",
              " 'single-partition',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'nor',\n",
              " 'yieldagreement',\n",
              " 'for',\n",
              " '$c$',\n",
              " 'obtained',\n",
              " 'by',\n",
              " 'using',\n",
              " 'the',\n",
              " 'two',\n",
              " 'methods.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordSet = set(bowA).union(set(bowB))"
      ],
      "metadata": {
        "id": "KjW7wnqDdOZQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordSet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GEiO0o_dQPQ",
        "outputId": "3e85b156-f895-4664-aa6b-4b993ac61abc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'',\n",
              " '\"$c$\"',\n",
              " '\"almostcorrectly\"',\n",
              " '\"newer\"',\n",
              " '$a/4$.',\n",
              " '$c$',\n",
              " \"'t\",\n",
              " '0.003,',\n",
              " '1,',\n",
              " '172$\\\\sim$173',\n",
              " '172.87$\\\\cdots$,',\n",
              " 'a',\n",
              " 'above',\n",
              " 'actually',\n",
              " 'adjust',\n",
              " 'also',\n",
              " 'an',\n",
              " 'and',\n",
              " 'approximation',\n",
              " 'aprevious',\n",
              " 'aproper',\n",
              " 'are',\n",
              " 'area',\n",
              " 'area,',\n",
              " 'article,',\n",
              " 'as',\n",
              " 'ashtekar',\n",
              " \"ashtekar's\",\n",
              " 'aspects',\n",
              " 'atomic',\n",
              " 'background',\n",
              " 'based',\n",
              " 'be',\n",
              " 'bekenstein-hawking',\n",
              " 'black',\n",
              " 'brick',\n",
              " 'by',\n",
              " 'calculation',\n",
              " 'chosen',\n",
              " 'close',\n",
              " 'closed.',\n",
              " 'conjecture',\n",
              " 'consider',\n",
              " 'consistent;',\n",
              " 'constant',\n",
              " 'constraintalgebra',\n",
              " 'context',\n",
              " 'continuation',\n",
              " 'correct',\n",
              " 'correctlyreproduces',\n",
              " 'corresponding',\n",
              " 'cosmological',\n",
              " 'counting',\n",
              " 'coupled',\n",
              " 'covariant',\n",
              " 'curved',\n",
              " 'cut-off',\n",
              " 'degeneracy',\n",
              " 'degeneracy.',\n",
              " 'derivation',\n",
              " 'derive',\n",
              " 'difference,',\n",
              " 'different',\n",
              " 'dimensions',\n",
              " 'discuss',\n",
              " 'discussions',\n",
              " 'divergence',\n",
              " 'divergent',\n",
              " 'divergent.',\n",
              " 'due',\n",
              " 'earlier.',\n",
              " 'electric',\n",
              " 'entropy',\n",
              " 'error',\n",
              " 'euclidean',\n",
              " 'evaluate',\n",
              " 'eventhorizon.',\n",
              " 'expected',\n",
              " 'explicitly',\n",
              " 'expression',\n",
              " 'field',\n",
              " 'field,',\n",
              " 'fieldentropy',\n",
              " 'fields',\n",
              " 'find',\n",
              " 'fitting',\n",
              " 'for',\n",
              " 'formula',\n",
              " 'formulafor',\n",
              " 'found',\n",
              " 'from',\n",
              " 'furthermore,',\n",
              " 'geometric',\n",
              " 'geometry',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'globally',\n",
              " 'gravitational',\n",
              " 'having',\n",
              " 'hawking',\n",
              " 'hole',\n",
              " 'hole,',\n",
              " 'holebackground',\n",
              " 'holeentropy',\n",
              " 'hooft.',\n",
              " 'horizon',\n",
              " 'horizon.',\n",
              " 'i.e.,',\n",
              " 'immirzi',\n",
              " 'important',\n",
              " 'in',\n",
              " 'incontrast',\n",
              " 'incurved',\n",
              " 'inparticular,',\n",
              " 'instead',\n",
              " 'inverse',\n",
              " 'is',\n",
              " 'largecompared',\n",
              " 'leading',\n",
              " 'leads',\n",
              " 'length',\n",
              " 'logarithmically',\n",
              " 'logarithmicdivergence',\n",
              " 'lorentzian',\n",
              " 'madeof',\n",
              " 'mathematically',\n",
              " 'matter',\n",
              " 'may',\n",
              " 'method',\n",
              " 'methods,we',\n",
              " 'methods.',\n",
              " 'methodyields',\n",
              " 'minimally',\n",
              " 'model',\n",
              " 'modes',\n",
              " 'modify',\n",
              " 'moreover,',\n",
              " 'nature',\n",
              " 'near-horizon',\n",
              " 'near-horizonregion.',\n",
              " 'new',\n",
              " 'nor',\n",
              " 'norm',\n",
              " 'not',\n",
              " 'numerical',\n",
              " 'obtain',\n",
              " 'obtained',\n",
              " 'of',\n",
              " 'ofthe',\n",
              " 'on',\n",
              " 'order',\n",
              " 'original',\n",
              " 'our',\n",
              " 'our\"new\"',\n",
              " 'out',\n",
              " 'paper',\n",
              " 'parameter',\n",
              " 'parameter,',\n",
              " 'parameter;',\n",
              " 'planck',\n",
              " 'pointing',\n",
              " 'power',\n",
              " 'predict',\n",
              " 'predictions',\n",
              " 'presence',\n",
              " 'previous',\n",
              " 'properties',\n",
              " 'proportional',\n",
              " 'proportionality',\n",
              " 'purpose,',\n",
              " 'quantization',\n",
              " 'radiation',\n",
              " 'regularizationschemes',\n",
              " 'related',\n",
              " 'remains',\n",
              " 'reproduce',\n",
              " 'rule',\n",
              " 'scalar',\n",
              " 'scale.',\n",
              " 'schwarzschild',\n",
              " 'second',\n",
              " 'sector',\n",
              " 'shell',\n",
              " 'show',\n",
              " 'significant',\n",
              " 'single',\n",
              " 'single-partition',\n",
              " 'solution',\n",
              " 'spaces.',\n",
              " 'spaces.the',\n",
              " 'spectra',\n",
              " 'spectrum',\n",
              " 'spectrum,',\n",
              " 'spectrum.',\n",
              " 'spectrum;',\n",
              " 'spectrumbased',\n",
              " 'states,',\n",
              " 'stationary.',\n",
              " 'strongly',\n",
              " 'suggest',\n",
              " 'surrounding',\n",
              " 'term',\n",
              " 'terms',\n",
              " 'that',\n",
              " 'the',\n",
              " 'thecut-off',\n",
              " 'theentropy',\n",
              " 'theextra',\n",
              " 'thefirst',\n",
              " 'theimmirzi',\n",
              " 'then,',\n",
              " 'thenorm',\n",
              " 'theright',\n",
              " 'thermodynamical',\n",
              " 'theschwarzschild',\n",
              " 'these',\n",
              " 'thewkb',\n",
              " 'thickness',\n",
              " 'thicknesssurrounding',\n",
              " 'thin',\n",
              " 'thinshell',\n",
              " 'this',\n",
              " 'to',\n",
              " 'together',\n",
              " 'totally',\n",
              " 'tothe',\n",
              " 'track.',\n",
              " 'two',\n",
              " 'unit',\n",
              " 'used',\n",
              " 'using',\n",
              " 'value',\n",
              " 'variables',\n",
              " 'variables,',\n",
              " 'variablesneither',\n",
              " 'very',\n",
              " 'wall',\n",
              " 'was',\n",
              " 'we',\n",
              " 'weconstruct',\n",
              " 'wewill',\n",
              " 'whenexpressed',\n",
              " 'which',\n",
              " 'while',\n",
              " 'will',\n",
              " 'with',\n",
              " 'without',\n",
              " 'wkb',\n",
              " 'yieldagreement',\n",
              " 'yielded$0.997\\\\cdots$,',\n",
              " 'yields'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordDictA = dict.fromkeys(wordSet, 0) \n",
        "wordDictB = dict.fromkeys(wordSet, 0) "
      ],
      "metadata": {
        "id": "ThaiBqGedUUe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordDictA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li811fj1dVsN",
        "outputId": "85210864-1577-4413-ab1c-0814e2ed9369"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '\"$c$\"': 0,\n",
              " '\"almostcorrectly\"': 0,\n",
              " '\"newer\"': 0,\n",
              " '$a/4$.': 0,\n",
              " '$c$': 0,\n",
              " \"'t\": 0,\n",
              " '0.003,': 0,\n",
              " '1,': 0,\n",
              " '172$\\\\sim$173': 0,\n",
              " '172.87$\\\\cdots$,': 0,\n",
              " 'a': 0,\n",
              " 'above': 0,\n",
              " 'actually': 0,\n",
              " 'adjust': 0,\n",
              " 'also': 0,\n",
              " 'an': 0,\n",
              " 'and': 0,\n",
              " 'approximation': 0,\n",
              " 'aprevious': 0,\n",
              " 'aproper': 0,\n",
              " 'are': 0,\n",
              " 'area': 0,\n",
              " 'area,': 0,\n",
              " 'article,': 0,\n",
              " 'as': 0,\n",
              " 'ashtekar': 0,\n",
              " \"ashtekar's\": 0,\n",
              " 'aspects': 0,\n",
              " 'atomic': 0,\n",
              " 'background': 0,\n",
              " 'based': 0,\n",
              " 'be': 0,\n",
              " 'bekenstein-hawking': 0,\n",
              " 'black': 0,\n",
              " 'brick': 0,\n",
              " 'by': 0,\n",
              " 'calculation': 0,\n",
              " 'chosen': 0,\n",
              " 'close': 0,\n",
              " 'closed.': 0,\n",
              " 'conjecture': 0,\n",
              " 'consider': 0,\n",
              " 'consistent;': 0,\n",
              " 'constant': 0,\n",
              " 'constraintalgebra': 0,\n",
              " 'context': 0,\n",
              " 'continuation': 0,\n",
              " 'correct': 0,\n",
              " 'correctlyreproduces': 0,\n",
              " 'corresponding': 0,\n",
              " 'cosmological': 0,\n",
              " 'counting': 0,\n",
              " 'coupled': 0,\n",
              " 'covariant': 0,\n",
              " 'curved': 0,\n",
              " 'cut-off': 0,\n",
              " 'degeneracy': 0,\n",
              " 'degeneracy.': 0,\n",
              " 'derivation': 0,\n",
              " 'derive': 0,\n",
              " 'difference,': 0,\n",
              " 'different': 0,\n",
              " 'dimensions': 0,\n",
              " 'discuss': 0,\n",
              " 'discussions': 0,\n",
              " 'divergence': 0,\n",
              " 'divergent': 0,\n",
              " 'divergent.': 0,\n",
              " 'due': 0,\n",
              " 'earlier.': 0,\n",
              " 'electric': 0,\n",
              " 'entropy': 0,\n",
              " 'error': 0,\n",
              " 'euclidean': 0,\n",
              " 'evaluate': 0,\n",
              " 'eventhorizon.': 0,\n",
              " 'expected': 0,\n",
              " 'explicitly': 0,\n",
              " 'expression': 0,\n",
              " 'field': 0,\n",
              " 'field,': 0,\n",
              " 'fieldentropy': 0,\n",
              " 'fields': 0,\n",
              " 'find': 0,\n",
              " 'fitting': 0,\n",
              " 'for': 0,\n",
              " 'formula': 0,\n",
              " 'formulafor': 0,\n",
              " 'found': 0,\n",
              " 'from': 0,\n",
              " 'furthermore,': 0,\n",
              " 'geometric': 0,\n",
              " 'geometry': 0,\n",
              " 'given': 0,\n",
              " 'gives': 0,\n",
              " 'globally': 0,\n",
              " 'gravitational': 0,\n",
              " 'having': 0,\n",
              " 'hawking': 0,\n",
              " 'hole': 0,\n",
              " 'hole,': 0,\n",
              " 'holebackground': 0,\n",
              " 'holeentropy': 0,\n",
              " 'hooft.': 0,\n",
              " 'horizon': 0,\n",
              " 'horizon.': 0,\n",
              " 'i.e.,': 0,\n",
              " 'immirzi': 0,\n",
              " 'important': 0,\n",
              " 'in': 0,\n",
              " 'incontrast': 0,\n",
              " 'incurved': 0,\n",
              " 'inparticular,': 0,\n",
              " 'instead': 0,\n",
              " 'inverse': 0,\n",
              " 'is': 0,\n",
              " 'largecompared': 0,\n",
              " 'leading': 0,\n",
              " 'leads': 0,\n",
              " 'length': 0,\n",
              " 'logarithmically': 0,\n",
              " 'logarithmicdivergence': 0,\n",
              " 'lorentzian': 0,\n",
              " 'madeof': 0,\n",
              " 'mathematically': 0,\n",
              " 'matter': 0,\n",
              " 'may': 0,\n",
              " 'method': 0,\n",
              " 'methods,we': 0,\n",
              " 'methods.': 0,\n",
              " 'methodyields': 0,\n",
              " 'minimally': 0,\n",
              " 'model': 0,\n",
              " 'modes': 0,\n",
              " 'modify': 0,\n",
              " 'moreover,': 0,\n",
              " 'nature': 0,\n",
              " 'near-horizon': 0,\n",
              " 'near-horizonregion.': 0,\n",
              " 'new': 0,\n",
              " 'nor': 0,\n",
              " 'norm': 0,\n",
              " 'not': 0,\n",
              " 'numerical': 0,\n",
              " 'obtain': 0,\n",
              " 'obtained': 0,\n",
              " 'of': 0,\n",
              " 'ofthe': 0,\n",
              " 'on': 0,\n",
              " 'order': 0,\n",
              " 'original': 0,\n",
              " 'our': 0,\n",
              " 'our\"new\"': 0,\n",
              " 'out': 0,\n",
              " 'paper': 0,\n",
              " 'parameter': 0,\n",
              " 'parameter,': 0,\n",
              " 'parameter;': 0,\n",
              " 'planck': 0,\n",
              " 'pointing': 0,\n",
              " 'power': 0,\n",
              " 'predict': 0,\n",
              " 'predictions': 0,\n",
              " 'presence': 0,\n",
              " 'previous': 0,\n",
              " 'properties': 0,\n",
              " 'proportional': 0,\n",
              " 'proportionality': 0,\n",
              " 'purpose,': 0,\n",
              " 'quantization': 0,\n",
              " 'radiation': 0,\n",
              " 'regularizationschemes': 0,\n",
              " 'related': 0,\n",
              " 'remains': 0,\n",
              " 'reproduce': 0,\n",
              " 'rule': 0,\n",
              " 'scalar': 0,\n",
              " 'scale.': 0,\n",
              " 'schwarzschild': 0,\n",
              " 'second': 0,\n",
              " 'sector': 0,\n",
              " 'shell': 0,\n",
              " 'show': 0,\n",
              " 'significant': 0,\n",
              " 'single': 0,\n",
              " 'single-partition': 0,\n",
              " 'solution': 0,\n",
              " 'spaces.': 0,\n",
              " 'spaces.the': 0,\n",
              " 'spectra': 0,\n",
              " 'spectrum': 0,\n",
              " 'spectrum,': 0,\n",
              " 'spectrum.': 0,\n",
              " 'spectrum;': 0,\n",
              " 'spectrumbased': 0,\n",
              " 'states,': 0,\n",
              " 'stationary.': 0,\n",
              " 'strongly': 0,\n",
              " 'suggest': 0,\n",
              " 'surrounding': 0,\n",
              " 'term': 0,\n",
              " 'terms': 0,\n",
              " 'that': 0,\n",
              " 'the': 0,\n",
              " 'thecut-off': 0,\n",
              " 'theentropy': 0,\n",
              " 'theextra': 0,\n",
              " 'thefirst': 0,\n",
              " 'theimmirzi': 0,\n",
              " 'then,': 0,\n",
              " 'thenorm': 0,\n",
              " 'theright': 0,\n",
              " 'thermodynamical': 0,\n",
              " 'theschwarzschild': 0,\n",
              " 'these': 0,\n",
              " 'thewkb': 0,\n",
              " 'thickness': 0,\n",
              " 'thicknesssurrounding': 0,\n",
              " 'thin': 0,\n",
              " 'thinshell': 0,\n",
              " 'this': 0,\n",
              " 'to': 0,\n",
              " 'together': 0,\n",
              " 'totally': 0,\n",
              " 'tothe': 0,\n",
              " 'track.': 0,\n",
              " 'two': 0,\n",
              " 'unit': 0,\n",
              " 'used': 0,\n",
              " 'using': 0,\n",
              " 'value': 0,\n",
              " 'variables': 0,\n",
              " 'variables,': 0,\n",
              " 'variablesneither': 0,\n",
              " 'very': 0,\n",
              " 'wall': 0,\n",
              " 'was': 0,\n",
              " 'we': 0,\n",
              " 'weconstruct': 0,\n",
              " 'wewill': 0,\n",
              " 'whenexpressed': 0,\n",
              " 'which': 0,\n",
              " 'while': 0,\n",
              " 'will': 0,\n",
              " 'with': 0,\n",
              " 'without': 0,\n",
              " 'wkb': 0,\n",
              " 'yieldagreement': 0,\n",
              " 'yielded$0.997\\\\cdots$,': 0,\n",
              " 'yields': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in bowA:\n",
        "    wordDictA[word]+=1\n",
        "    \n",
        "for word in bowB:\n",
        "    wordDictB[word]+=1"
      ],
      "metadata": {
        "id": "Cq6sDcKGdYHY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordDictA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C39ocVCfdZjm",
        "outputId": "6b38d46e-00a1-4589-cded-19ef19bbf5d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 1,\n",
              " '\"$c$\"': 0,\n",
              " '\"almostcorrectly\"': 0,\n",
              " '\"newer\"': 0,\n",
              " '$a/4$.': 0,\n",
              " '$c$': 0,\n",
              " \"'t\": 1,\n",
              " '0.003,': 0,\n",
              " '1,': 0,\n",
              " '172$\\\\sim$173': 0,\n",
              " '172.87$\\\\cdots$,': 0,\n",
              " 'a': 9,\n",
              " 'above': 1,\n",
              " 'actually': 0,\n",
              " 'adjust': 0,\n",
              " 'also': 1,\n",
              " 'an': 2,\n",
              " 'and': 4,\n",
              " 'approximation': 1,\n",
              " 'aprevious': 1,\n",
              " 'aproper': 1,\n",
              " 'are': 4,\n",
              " 'area': 2,\n",
              " 'area,': 0,\n",
              " 'article,': 4,\n",
              " 'as': 0,\n",
              " 'ashtekar': 0,\n",
              " \"ashtekar's\": 0,\n",
              " 'aspects': 1,\n",
              " 'atomic': 1,\n",
              " 'background': 1,\n",
              " 'based': 0,\n",
              " 'be': 2,\n",
              " 'bekenstein-hawking': 0,\n",
              " 'black': 5,\n",
              " 'brick': 2,\n",
              " 'by': 1,\n",
              " 'calculation': 1,\n",
              " 'chosen': 1,\n",
              " 'close': 0,\n",
              " 'closed.': 0,\n",
              " 'conjecture': 0,\n",
              " 'consider': 1,\n",
              " 'consistent;': 0,\n",
              " 'constant': 0,\n",
              " 'constraintalgebra': 0,\n",
              " 'context': 1,\n",
              " 'continuation': 1,\n",
              " 'correct': 0,\n",
              " 'correctlyreproduces': 0,\n",
              " 'corresponding': 1,\n",
              " 'cosmological': 1,\n",
              " 'counting': 1,\n",
              " 'coupled': 2,\n",
              " 'covariant': 1,\n",
              " 'curved': 1,\n",
              " 'cut-off': 2,\n",
              " 'degeneracy': 0,\n",
              " 'degeneracy.': 0,\n",
              " 'derivation': 0,\n",
              " 'derive': 0,\n",
              " 'difference,': 0,\n",
              " 'different': 0,\n",
              " 'dimensions': 0,\n",
              " 'discuss': 1,\n",
              " 'discussions': 2,\n",
              " 'divergence': 1,\n",
              " 'divergent': 2,\n",
              " 'divergent.': 1,\n",
              " 'due': 0,\n",
              " 'earlier.': 1,\n",
              " 'electric': 0,\n",
              " 'entropy': 4,\n",
              " 'error': 0,\n",
              " 'euclidean': 1,\n",
              " 'evaluate': 1,\n",
              " 'eventhorizon.': 1,\n",
              " 'expected': 1,\n",
              " 'explicitly': 0,\n",
              " 'expression': 3,\n",
              " 'field': 4,\n",
              " 'field,': 0,\n",
              " 'fieldentropy': 1,\n",
              " 'fields': 1,\n",
              " 'find': 1,\n",
              " 'fitting': 0,\n",
              " 'for': 2,\n",
              " 'formula': 0,\n",
              " 'formulafor': 0,\n",
              " 'found': 1,\n",
              " 'from': 1,\n",
              " 'furthermore,': 0,\n",
              " 'geometric': 1,\n",
              " 'geometry': 1,\n",
              " 'given': 3,\n",
              " 'gives': 0,\n",
              " 'globally': 1,\n",
              " 'gravitational': 0,\n",
              " 'having': 0,\n",
              " 'hawking': 0,\n",
              " 'hole': 4,\n",
              " 'hole,': 0,\n",
              " 'holebackground': 1,\n",
              " 'holeentropy': 0,\n",
              " 'hooft.': 1,\n",
              " 'horizon': 1,\n",
              " 'horizon.': 3,\n",
              " 'i.e.,': 0,\n",
              " 'immirzi': 0,\n",
              " 'important': 1,\n",
              " 'in': 13,\n",
              " 'incontrast': 1,\n",
              " 'incurved': 1,\n",
              " 'inparticular,': 0,\n",
              " 'instead': 0,\n",
              " 'inverse': 1,\n",
              " 'is': 6,\n",
              " 'largecompared': 1,\n",
              " 'leading': 1,\n",
              " 'leads': 1,\n",
              " 'length': 1,\n",
              " 'logarithmically': 2,\n",
              " 'logarithmicdivergence': 1,\n",
              " 'lorentzian': 1,\n",
              " 'madeof': 0,\n",
              " 'mathematically': 0,\n",
              " 'matter': 3,\n",
              " 'may': 0,\n",
              " 'method': 0,\n",
              " 'methods,we': 0,\n",
              " 'methods.': 0,\n",
              " 'methodyields': 0,\n",
              " 'minimally': 2,\n",
              " 'model': 1,\n",
              " 'modes': 1,\n",
              " 'modify': 0,\n",
              " 'moreover,': 0,\n",
              " 'nature': 1,\n",
              " 'near-horizon': 1,\n",
              " 'near-horizonregion.': 1,\n",
              " 'new': 1,\n",
              " 'nor': 0,\n",
              " 'norm': 0,\n",
              " 'not': 1,\n",
              " 'numerical': 0,\n",
              " 'obtain': 0,\n",
              " 'obtained': 1,\n",
              " 'of': 20,\n",
              " 'ofthe': 2,\n",
              " 'on': 0,\n",
              " 'order': 2,\n",
              " 'original': 1,\n",
              " 'our': 0,\n",
              " 'our\"new\"': 0,\n",
              " 'out': 0,\n",
              " 'paper': 0,\n",
              " 'parameter': 2,\n",
              " 'parameter,': 1,\n",
              " 'parameter;': 0,\n",
              " 'planck': 1,\n",
              " 'pointing': 0,\n",
              " 'power': 1,\n",
              " 'predict': 0,\n",
              " 'predictions': 0,\n",
              " 'presence': 1,\n",
              " 'previous': 0,\n",
              " 'properties': 1,\n",
              " 'proportional': 2,\n",
              " 'proportionality': 0,\n",
              " 'purpose,': 0,\n",
              " 'quantization': 1,\n",
              " 'radiation': 0,\n",
              " 'regularizationschemes': 1,\n",
              " 'related': 1,\n",
              " 'remains': 1,\n",
              " 'reproduce': 0,\n",
              " 'rule': 1,\n",
              " 'scalar': 3,\n",
              " 'scale.': 1,\n",
              " 'schwarzschild': 2,\n",
              " 'second': 0,\n",
              " 'sector': 2,\n",
              " 'shell': 1,\n",
              " 'show': 0,\n",
              " 'significant': 1,\n",
              " 'single': 0,\n",
              " 'single-partition': 0,\n",
              " 'solution': 1,\n",
              " 'spaces.': 1,\n",
              " 'spaces.the': 1,\n",
              " 'spectra': 0,\n",
              " 'spectrum': 0,\n",
              " 'spectrum,': 0,\n",
              " 'spectrum.': 0,\n",
              " 'spectrum;': 0,\n",
              " 'spectrumbased': 0,\n",
              " 'states,': 1,\n",
              " 'stationary.': 1,\n",
              " 'strongly': 0,\n",
              " 'suggest': 0,\n",
              " 'surrounding': 1,\n",
              " 'term': 1,\n",
              " 'terms': 1,\n",
              " 'that': 3,\n",
              " 'the': 31,\n",
              " 'thecut-off': 1,\n",
              " 'theentropy': 1,\n",
              " 'theextra': 0,\n",
              " 'thefirst': 0,\n",
              " 'theimmirzi': 0,\n",
              " 'then,': 0,\n",
              " 'thenorm': 0,\n",
              " 'theright': 0,\n",
              " 'thermodynamical': 1,\n",
              " 'theschwarzschild': 1,\n",
              " 'these': 2,\n",
              " 'thewkb': 1,\n",
              " 'thickness': 2,\n",
              " 'thicknesssurrounding': 1,\n",
              " 'thin': 1,\n",
              " 'thinshell': 1,\n",
              " 'this': 3,\n",
              " 'to': 7,\n",
              " 'together': 1,\n",
              " 'totally': 0,\n",
              " 'tothe': 1,\n",
              " 'track.': 0,\n",
              " 'two': 0,\n",
              " 'unit': 0,\n",
              " 'used': 2,\n",
              " 'using': 1,\n",
              " 'value': 0,\n",
              " 'variables': 0,\n",
              " 'variables,': 0,\n",
              " 'variablesneither': 0,\n",
              " 'very': 0,\n",
              " 'wall': 2,\n",
              " 'was': 1,\n",
              " 'we': 3,\n",
              " 'weconstruct': 0,\n",
              " 'wewill': 1,\n",
              " 'whenexpressed': 1,\n",
              " 'which': 1,\n",
              " 'while': 0,\n",
              " 'will': 2,\n",
              " 'with': 3,\n",
              " 'without': 0,\n",
              " 'wkb': 1,\n",
              " 'yieldagreement': 0,\n",
              " 'yielded$0.997\\\\cdots$,': 0,\n",
              " 'yields': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame([wordDictA, wordDictB])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "KBhxCMtedb6-",
        "outputId": "443ed49d-5dee-499b-99e0-95e682ea72b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      norm  stationary.  thicknesssurrounding  ashtekar  actually  moreover,  \\\n",
              "0  1     0            1                     1         0         0          0   \n",
              "1  1     1            0                     0         1         1          1   \n",
              "\n",
              "   corresponding  earlier.  1,  ...  related  geometric  is  immirzi  \\\n",
              "0              1         1   0  ...        1          1   6        0   \n",
              "1              0         0   1  ...        1          0   4        1   \n",
              "\n",
              "   significant  whenexpressed  theright  article,  explicitly  largecompared  \n",
              "0            1              1         0         4           0              1  \n",
              "1            0              0         1         0           1              0  \n",
              "\n",
              "[2 rows x 251 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e56b8284-c51a-43cf-8eb5-384d71cb6d34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>norm</th>\n",
              "      <th>stationary.</th>\n",
              "      <th>thicknesssurrounding</th>\n",
              "      <th>ashtekar</th>\n",
              "      <th>actually</th>\n",
              "      <th>moreover,</th>\n",
              "      <th>corresponding</th>\n",
              "      <th>earlier.</th>\n",
              "      <th>1,</th>\n",
              "      <th>...</th>\n",
              "      <th>related</th>\n",
              "      <th>geometric</th>\n",
              "      <th>is</th>\n",
              "      <th>immirzi</th>\n",
              "      <th>significant</th>\n",
              "      <th>whenexpressed</th>\n",
              "      <th>theright</th>\n",
              "      <th>article,</th>\n",
              "      <th>explicitly</th>\n",
              "      <th>largecompared</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 251 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e56b8284-c51a-43cf-8eb5-384d71cb6d34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e56b8284-c51a-43cf-8eb5-384d71cb6d34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e56b8284-c51a-43cf-8eb5-384d71cb6d34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTF(wordDict, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict"
      ],
      "metadata": {
        "id": "9wxqfAmAdgZz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfBowA = computeTF(wordDictA, bowA)\n",
        "tfBowB = computeTF(wordDictB, bowB)"
      ],
      "metadata": {
        "id": "M5bkAwJNdjGJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfBowA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdxXMTC5dkhN",
        "outputId": "19b0bccc-4862-47d1-b37d-95198a8569db"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0.0035460992907801418,\n",
              " '\"$c$\"': 0.0,\n",
              " '\"almostcorrectly\"': 0.0,\n",
              " '\"newer\"': 0.0,\n",
              " '$a/4$.': 0.0,\n",
              " '$c$': 0.0,\n",
              " \"'t\": 0.0035460992907801418,\n",
              " '0.003,': 0.0,\n",
              " '1,': 0.0,\n",
              " '172$\\\\sim$173': 0.0,\n",
              " '172.87$\\\\cdots$,': 0.0,\n",
              " 'a': 0.031914893617021274,\n",
              " 'above': 0.0035460992907801418,\n",
              " 'actually': 0.0,\n",
              " 'adjust': 0.0,\n",
              " 'also': 0.0035460992907801418,\n",
              " 'an': 0.0070921985815602835,\n",
              " 'and': 0.014184397163120567,\n",
              " 'approximation': 0.0035460992907801418,\n",
              " 'aprevious': 0.0035460992907801418,\n",
              " 'aproper': 0.0035460992907801418,\n",
              " 'are': 0.014184397163120567,\n",
              " 'area': 0.0070921985815602835,\n",
              " 'area,': 0.0,\n",
              " 'article,': 0.014184397163120567,\n",
              " 'as': 0.0,\n",
              " 'ashtekar': 0.0,\n",
              " \"ashtekar's\": 0.0,\n",
              " 'aspects': 0.0035460992907801418,\n",
              " 'atomic': 0.0035460992907801418,\n",
              " 'background': 0.0035460992907801418,\n",
              " 'based': 0.0,\n",
              " 'be': 0.0070921985815602835,\n",
              " 'bekenstein-hawking': 0.0,\n",
              " 'black': 0.01773049645390071,\n",
              " 'brick': 0.0070921985815602835,\n",
              " 'by': 0.0035460992907801418,\n",
              " 'calculation': 0.0035460992907801418,\n",
              " 'chosen': 0.0035460992907801418,\n",
              " 'close': 0.0,\n",
              " 'closed.': 0.0,\n",
              " 'conjecture': 0.0,\n",
              " 'consider': 0.0035460992907801418,\n",
              " 'consistent;': 0.0,\n",
              " 'constant': 0.0,\n",
              " 'constraintalgebra': 0.0,\n",
              " 'context': 0.0035460992907801418,\n",
              " 'continuation': 0.0035460992907801418,\n",
              " 'correct': 0.0,\n",
              " 'correctlyreproduces': 0.0,\n",
              " 'corresponding': 0.0035460992907801418,\n",
              " 'cosmological': 0.0035460992907801418,\n",
              " 'counting': 0.0035460992907801418,\n",
              " 'coupled': 0.0070921985815602835,\n",
              " 'covariant': 0.0035460992907801418,\n",
              " 'curved': 0.0035460992907801418,\n",
              " 'cut-off': 0.0070921985815602835,\n",
              " 'degeneracy': 0.0,\n",
              " 'degeneracy.': 0.0,\n",
              " 'derivation': 0.0,\n",
              " 'derive': 0.0,\n",
              " 'difference,': 0.0,\n",
              " 'different': 0.0,\n",
              " 'dimensions': 0.0,\n",
              " 'discuss': 0.0035460992907801418,\n",
              " 'discussions': 0.0070921985815602835,\n",
              " 'divergence': 0.0035460992907801418,\n",
              " 'divergent': 0.0070921985815602835,\n",
              " 'divergent.': 0.0035460992907801418,\n",
              " 'due': 0.0,\n",
              " 'earlier.': 0.0035460992907801418,\n",
              " 'electric': 0.0,\n",
              " 'entropy': 0.014184397163120567,\n",
              " 'error': 0.0,\n",
              " 'euclidean': 0.0035460992907801418,\n",
              " 'evaluate': 0.0035460992907801418,\n",
              " 'eventhorizon.': 0.0035460992907801418,\n",
              " 'expected': 0.0035460992907801418,\n",
              " 'explicitly': 0.0,\n",
              " 'expression': 0.010638297872340425,\n",
              " 'field': 0.014184397163120567,\n",
              " 'field,': 0.0,\n",
              " 'fieldentropy': 0.0035460992907801418,\n",
              " 'fields': 0.0035460992907801418,\n",
              " 'find': 0.0035460992907801418,\n",
              " 'fitting': 0.0,\n",
              " 'for': 0.0070921985815602835,\n",
              " 'formula': 0.0,\n",
              " 'formulafor': 0.0,\n",
              " 'found': 0.0035460992907801418,\n",
              " 'from': 0.0035460992907801418,\n",
              " 'furthermore,': 0.0,\n",
              " 'geometric': 0.0035460992907801418,\n",
              " 'geometry': 0.0035460992907801418,\n",
              " 'given': 0.010638297872340425,\n",
              " 'gives': 0.0,\n",
              " 'globally': 0.0035460992907801418,\n",
              " 'gravitational': 0.0,\n",
              " 'having': 0.0,\n",
              " 'hawking': 0.0,\n",
              " 'hole': 0.014184397163120567,\n",
              " 'hole,': 0.0,\n",
              " 'holebackground': 0.0035460992907801418,\n",
              " 'holeentropy': 0.0,\n",
              " 'hooft.': 0.0035460992907801418,\n",
              " 'horizon': 0.0035460992907801418,\n",
              " 'horizon.': 0.010638297872340425,\n",
              " 'i.e.,': 0.0,\n",
              " 'immirzi': 0.0,\n",
              " 'important': 0.0035460992907801418,\n",
              " 'in': 0.04609929078014184,\n",
              " 'incontrast': 0.0035460992907801418,\n",
              " 'incurved': 0.0035460992907801418,\n",
              " 'inparticular,': 0.0,\n",
              " 'instead': 0.0,\n",
              " 'inverse': 0.0035460992907801418,\n",
              " 'is': 0.02127659574468085,\n",
              " 'largecompared': 0.0035460992907801418,\n",
              " 'leading': 0.0035460992907801418,\n",
              " 'leads': 0.0035460992907801418,\n",
              " 'length': 0.0035460992907801418,\n",
              " 'logarithmically': 0.0070921985815602835,\n",
              " 'logarithmicdivergence': 0.0035460992907801418,\n",
              " 'lorentzian': 0.0035460992907801418,\n",
              " 'madeof': 0.0,\n",
              " 'mathematically': 0.0,\n",
              " 'matter': 0.010638297872340425,\n",
              " 'may': 0.0,\n",
              " 'method': 0.0,\n",
              " 'methods,we': 0.0,\n",
              " 'methods.': 0.0,\n",
              " 'methodyields': 0.0,\n",
              " 'minimally': 0.0070921985815602835,\n",
              " 'model': 0.0035460992907801418,\n",
              " 'modes': 0.0035460992907801418,\n",
              " 'modify': 0.0,\n",
              " 'moreover,': 0.0,\n",
              " 'nature': 0.0035460992907801418,\n",
              " 'near-horizon': 0.0035460992907801418,\n",
              " 'near-horizonregion.': 0.0035460992907801418,\n",
              " 'new': 0.0035460992907801418,\n",
              " 'nor': 0.0,\n",
              " 'norm': 0.0,\n",
              " 'not': 0.0035460992907801418,\n",
              " 'numerical': 0.0,\n",
              " 'obtain': 0.0,\n",
              " 'obtained': 0.0035460992907801418,\n",
              " 'of': 0.07092198581560284,\n",
              " 'ofthe': 0.0070921985815602835,\n",
              " 'on': 0.0,\n",
              " 'order': 0.0070921985815602835,\n",
              " 'original': 0.0035460992907801418,\n",
              " 'our': 0.0,\n",
              " 'our\"new\"': 0.0,\n",
              " 'out': 0.0,\n",
              " 'paper': 0.0,\n",
              " 'parameter': 0.0070921985815602835,\n",
              " 'parameter,': 0.0035460992907801418,\n",
              " 'parameter;': 0.0,\n",
              " 'planck': 0.0035460992907801418,\n",
              " 'pointing': 0.0,\n",
              " 'power': 0.0035460992907801418,\n",
              " 'predict': 0.0,\n",
              " 'predictions': 0.0,\n",
              " 'presence': 0.0035460992907801418,\n",
              " 'previous': 0.0,\n",
              " 'properties': 0.0035460992907801418,\n",
              " 'proportional': 0.0070921985815602835,\n",
              " 'proportionality': 0.0,\n",
              " 'purpose,': 0.0,\n",
              " 'quantization': 0.0035460992907801418,\n",
              " 'radiation': 0.0,\n",
              " 'regularizationschemes': 0.0035460992907801418,\n",
              " 'related': 0.0035460992907801418,\n",
              " 'remains': 0.0035460992907801418,\n",
              " 'reproduce': 0.0,\n",
              " 'rule': 0.0035460992907801418,\n",
              " 'scalar': 0.010638297872340425,\n",
              " 'scale.': 0.0035460992907801418,\n",
              " 'schwarzschild': 0.0070921985815602835,\n",
              " 'second': 0.0,\n",
              " 'sector': 0.0070921985815602835,\n",
              " 'shell': 0.0035460992907801418,\n",
              " 'show': 0.0,\n",
              " 'significant': 0.0035460992907801418,\n",
              " 'single': 0.0,\n",
              " 'single-partition': 0.0,\n",
              " 'solution': 0.0035460992907801418,\n",
              " 'spaces.': 0.0035460992907801418,\n",
              " 'spaces.the': 0.0035460992907801418,\n",
              " 'spectra': 0.0,\n",
              " 'spectrum': 0.0,\n",
              " 'spectrum,': 0.0,\n",
              " 'spectrum.': 0.0,\n",
              " 'spectrum;': 0.0,\n",
              " 'spectrumbased': 0.0,\n",
              " 'states,': 0.0035460992907801418,\n",
              " 'stationary.': 0.0035460992907801418,\n",
              " 'strongly': 0.0,\n",
              " 'suggest': 0.0,\n",
              " 'surrounding': 0.0035460992907801418,\n",
              " 'term': 0.0035460992907801418,\n",
              " 'terms': 0.0035460992907801418,\n",
              " 'that': 0.010638297872340425,\n",
              " 'the': 0.1099290780141844,\n",
              " 'thecut-off': 0.0035460992907801418,\n",
              " 'theentropy': 0.0035460992907801418,\n",
              " 'theextra': 0.0,\n",
              " 'thefirst': 0.0,\n",
              " 'theimmirzi': 0.0,\n",
              " 'then,': 0.0,\n",
              " 'thenorm': 0.0,\n",
              " 'theright': 0.0,\n",
              " 'thermodynamical': 0.0035460992907801418,\n",
              " 'theschwarzschild': 0.0035460992907801418,\n",
              " 'these': 0.0070921985815602835,\n",
              " 'thewkb': 0.0035460992907801418,\n",
              " 'thickness': 0.0070921985815602835,\n",
              " 'thicknesssurrounding': 0.0035460992907801418,\n",
              " 'thin': 0.0035460992907801418,\n",
              " 'thinshell': 0.0035460992907801418,\n",
              " 'this': 0.010638297872340425,\n",
              " 'to': 0.024822695035460994,\n",
              " 'together': 0.0035460992907801418,\n",
              " 'totally': 0.0,\n",
              " 'tothe': 0.0035460992907801418,\n",
              " 'track.': 0.0,\n",
              " 'two': 0.0,\n",
              " 'unit': 0.0,\n",
              " 'used': 0.0070921985815602835,\n",
              " 'using': 0.0035460992907801418,\n",
              " 'value': 0.0,\n",
              " 'variables': 0.0,\n",
              " 'variables,': 0.0,\n",
              " 'variablesneither': 0.0,\n",
              " 'very': 0.0,\n",
              " 'wall': 0.0070921985815602835,\n",
              " 'was': 0.0035460992907801418,\n",
              " 'we': 0.010638297872340425,\n",
              " 'weconstruct': 0.0,\n",
              " 'wewill': 0.0035460992907801418,\n",
              " 'whenexpressed': 0.0035460992907801418,\n",
              " 'which': 0.0035460992907801418,\n",
              " 'while': 0.0,\n",
              " 'will': 0.0070921985815602835,\n",
              " 'with': 0.010638297872340425,\n",
              " 'without': 0.0,\n",
              " 'wkb': 0.0035460992907801418,\n",
              " 'yieldagreement': 0.0,\n",
              " 'yielded$0.997\\\\cdots$,': 0.0,\n",
              " 'yields': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfBowB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjzzCvSqdmH5",
        "outputId": "1645e05c-ab3a-4359-c06d-3a1259c98a3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0.004098360655737705,\n",
              " '\"$c$\"': 0.004098360655737705,\n",
              " '\"almostcorrectly\"': 0.004098360655737705,\n",
              " '\"newer\"': 0.00819672131147541,\n",
              " '$a/4$.': 0.004098360655737705,\n",
              " '$c$': 0.004098360655737705,\n",
              " \"'t\": 0.0,\n",
              " '0.003,': 0.004098360655737705,\n",
              " '1,': 0.004098360655737705,\n",
              " '172$\\\\sim$173': 0.004098360655737705,\n",
              " '172.87$\\\\cdots$,': 0.004098360655737705,\n",
              " 'a': 0.028688524590163935,\n",
              " 'above': 0.0,\n",
              " 'actually': 0.004098360655737705,\n",
              " 'adjust': 0.004098360655737705,\n",
              " 'also': 0.004098360655737705,\n",
              " 'an': 0.004098360655737705,\n",
              " 'and': 0.00819672131147541,\n",
              " 'approximation': 0.0,\n",
              " 'aprevious': 0.0,\n",
              " 'aproper': 0.0,\n",
              " 'are': 0.004098360655737705,\n",
              " 'area': 0.03278688524590164,\n",
              " 'area,': 0.004098360655737705,\n",
              " 'article,': 0.0,\n",
              " 'as': 0.004098360655737705,\n",
              " 'ashtekar': 0.004098360655737705,\n",
              " \"ashtekar's\": 0.00819672131147541,\n",
              " 'aspects': 0.0,\n",
              " 'atomic': 0.0,\n",
              " 'background': 0.0,\n",
              " 'based': 0.012295081967213115,\n",
              " 'be': 0.0,\n",
              " 'bekenstein-hawking': 0.004098360655737705,\n",
              " 'black': 0.02459016393442623,\n",
              " 'brick': 0.0,\n",
              " 'by': 0.01639344262295082,\n",
              " 'calculation': 0.0,\n",
              " 'chosen': 0.0,\n",
              " 'close': 0.004098360655737705,\n",
              " 'closed.': 0.004098360655737705,\n",
              " 'conjecture': 0.004098360655737705,\n",
              " 'consider': 0.0,\n",
              " 'consistent;': 0.004098360655737705,\n",
              " 'constant': 0.004098360655737705,\n",
              " 'constraintalgebra': 0.004098360655737705,\n",
              " 'context': 0.0,\n",
              " 'continuation': 0.0,\n",
              " 'correct': 0.004098360655737705,\n",
              " 'correctlyreproduces': 0.004098360655737705,\n",
              " 'corresponding': 0.0,\n",
              " 'cosmological': 0.0,\n",
              " 'counting': 0.0,\n",
              " 'coupled': 0.0,\n",
              " 'covariant': 0.0,\n",
              " 'curved': 0.0,\n",
              " 'cut-off': 0.0,\n",
              " 'degeneracy': 0.00819672131147541,\n",
              " 'degeneracy.': 0.00819672131147541,\n",
              " 'derivation': 0.004098360655737705,\n",
              " 'derive': 0.004098360655737705,\n",
              " 'difference,': 0.004098360655737705,\n",
              " 'different': 0.004098360655737705,\n",
              " 'dimensions': 0.004098360655737705,\n",
              " 'discuss': 0.0,\n",
              " 'discussions': 0.0,\n",
              " 'divergence': 0.0,\n",
              " 'divergent': 0.0,\n",
              " 'divergent.': 0.0,\n",
              " 'due': 0.004098360655737705,\n",
              " 'earlier.': 0.0,\n",
              " 'electric': 0.00819672131147541,\n",
              " 'entropy': 0.00819672131147541,\n",
              " 'error': 0.004098360655737705,\n",
              " 'euclidean': 0.0,\n",
              " 'evaluate': 0.0,\n",
              " 'eventhorizon.': 0.0,\n",
              " 'expected': 0.004098360655737705,\n",
              " 'explicitly': 0.004098360655737705,\n",
              " 'expression': 0.0,\n",
              " 'field': 0.004098360655737705,\n",
              " 'field,': 0.004098360655737705,\n",
              " 'fieldentropy': 0.0,\n",
              " 'fields': 0.0,\n",
              " 'find': 0.0,\n",
              " 'fitting': 0.004098360655737705,\n",
              " 'for': 0.012295081967213115,\n",
              " 'formula': 0.004098360655737705,\n",
              " 'formulafor': 0.004098360655737705,\n",
              " 'found': 0.0,\n",
              " 'from': 0.0,\n",
              " 'furthermore,': 0.004098360655737705,\n",
              " 'geometric': 0.0,\n",
              " 'geometry': 0.0,\n",
              " 'given': 0.004098360655737705,\n",
              " 'gives': 0.004098360655737705,\n",
              " 'globally': 0.0,\n",
              " 'gravitational': 0.00819672131147541,\n",
              " 'having': 0.004098360655737705,\n",
              " 'hawking': 0.004098360655737705,\n",
              " 'hole': 0.01639344262295082,\n",
              " 'hole,': 0.004098360655737705,\n",
              " 'holebackground': 0.0,\n",
              " 'holeentropy': 0.004098360655737705,\n",
              " 'hooft.': 0.0,\n",
              " 'horizon': 0.0,\n",
              " 'horizon.': 0.0,\n",
              " 'i.e.,': 0.004098360655737705,\n",
              " 'immirzi': 0.004098360655737705,\n",
              " 'important': 0.0,\n",
              " 'in': 0.00819672131147541,\n",
              " 'incontrast': 0.0,\n",
              " 'incurved': 0.0,\n",
              " 'inparticular,': 0.004098360655737705,\n",
              " 'instead': 0.004098360655737705,\n",
              " 'inverse': 0.0,\n",
              " 'is': 0.01639344262295082,\n",
              " 'largecompared': 0.0,\n",
              " 'leading': 0.0,\n",
              " 'leads': 0.0,\n",
              " 'length': 0.0,\n",
              " 'logarithmically': 0.0,\n",
              " 'logarithmicdivergence': 0.0,\n",
              " 'lorentzian': 0.0,\n",
              " 'madeof': 0.004098360655737705,\n",
              " 'mathematically': 0.004098360655737705,\n",
              " 'matter': 0.0,\n",
              " 'may': 0.004098360655737705,\n",
              " 'method': 0.004098360655737705,\n",
              " 'methods,we': 0.004098360655737705,\n",
              " 'methods.': 0.004098360655737705,\n",
              " 'methodyields': 0.004098360655737705,\n",
              " 'minimally': 0.0,\n",
              " 'model': 0.0,\n",
              " 'modes': 0.0,\n",
              " 'modify': 0.004098360655737705,\n",
              " 'moreover,': 0.004098360655737705,\n",
              " 'nature': 0.0,\n",
              " 'near-horizon': 0.0,\n",
              " 'near-horizonregion.': 0.0,\n",
              " 'new': 0.00819672131147541,\n",
              " 'nor': 0.004098360655737705,\n",
              " 'norm': 0.004098360655737705,\n",
              " 'not': 0.0,\n",
              " 'numerical': 0.004098360655737705,\n",
              " 'obtain': 0.004098360655737705,\n",
              " 'obtained': 0.004098360655737705,\n",
              " 'of': 0.02459016393442623,\n",
              " 'ofthe': 0.0,\n",
              " 'on': 0.020491803278688523,\n",
              " 'order': 0.0,\n",
              " 'original': 0.0,\n",
              " 'our': 0.020491803278688523,\n",
              " 'our\"new\"': 0.004098360655737705,\n",
              " 'out': 0.004098360655737705,\n",
              " 'paper': 0.004098360655737705,\n",
              " 'parameter': 0.004098360655737705,\n",
              " 'parameter,': 0.0,\n",
              " 'parameter;': 0.004098360655737705,\n",
              " 'planck': 0.0,\n",
              " 'pointing': 0.004098360655737705,\n",
              " 'power': 0.0,\n",
              " 'predict': 0.004098360655737705,\n",
              " 'predictions': 0.004098360655737705,\n",
              " 'presence': 0.0,\n",
              " 'previous': 0.004098360655737705,\n",
              " 'properties': 0.0,\n",
              " 'proportional': 0.0,\n",
              " 'proportionality': 0.004098360655737705,\n",
              " 'purpose,': 0.004098360655737705,\n",
              " 'quantization': 0.0,\n",
              " 'radiation': 0.004098360655737705,\n",
              " 'regularizationschemes': 0.0,\n",
              " 'related': 0.004098360655737705,\n",
              " 'remains': 0.0,\n",
              " 'reproduce': 0.004098360655737705,\n",
              " 'rule': 0.0,\n",
              " 'scalar': 0.0,\n",
              " 'scale.': 0.0,\n",
              " 'schwarzschild': 0.0,\n",
              " 'second': 0.004098360655737705,\n",
              " 'sector': 0.0,\n",
              " 'shell': 0.0,\n",
              " 'show': 0.01639344262295082,\n",
              " 'significant': 0.0,\n",
              " 'single': 0.004098360655737705,\n",
              " 'single-partition': 0.012295081967213115,\n",
              " 'solution': 0.0,\n",
              " 'spaces.': 0.0,\n",
              " 'spaces.the': 0.0,\n",
              " 'spectra': 0.004098360655737705,\n",
              " 'spectrum': 0.00819672131147541,\n",
              " 'spectrum,': 0.004098360655737705,\n",
              " 'spectrum.': 0.00819672131147541,\n",
              " 'spectrum;': 0.004098360655737705,\n",
              " 'spectrumbased': 0.004098360655737705,\n",
              " 'states,': 0.0,\n",
              " 'stationary.': 0.0,\n",
              " 'strongly': 0.004098360655737705,\n",
              " 'suggest': 0.00819672131147541,\n",
              " 'surrounding': 0.0,\n",
              " 'term': 0.0,\n",
              " 'terms': 0.0,\n",
              " 'that': 0.028688524590163935,\n",
              " 'the': 0.0778688524590164,\n",
              " 'thecut-off': 0.0,\n",
              " 'theentropy': 0.0,\n",
              " 'theextra': 0.004098360655737705,\n",
              " 'thefirst': 0.004098360655737705,\n",
              " 'theimmirzi': 0.004098360655737705,\n",
              " 'then,': 0.004098360655737705,\n",
              " 'thenorm': 0.004098360655737705,\n",
              " 'theright': 0.004098360655737705,\n",
              " 'thermodynamical': 0.0,\n",
              " 'theschwarzschild': 0.0,\n",
              " 'these': 0.0,\n",
              " 'thewkb': 0.0,\n",
              " 'thickness': 0.0,\n",
              " 'thicknesssurrounding': 0.0,\n",
              " 'thin': 0.0,\n",
              " 'thinshell': 0.0,\n",
              " 'this': 0.00819672131147541,\n",
              " 'to': 0.01639344262295082,\n",
              " 'together': 0.0,\n",
              " 'totally': 0.004098360655737705,\n",
              " 'tothe': 0.0,\n",
              " 'track.': 0.004098360655737705,\n",
              " 'two': 0.00819672131147541,\n",
              " 'unit': 0.004098360655737705,\n",
              " 'used': 0.0,\n",
              " 'using': 0.012295081967213115,\n",
              " 'value': 0.004098360655737705,\n",
              " 'variables': 0.004098360655737705,\n",
              " 'variables,': 0.00819672131147541,\n",
              " 'variablesneither': 0.004098360655737705,\n",
              " 'very': 0.004098360655737705,\n",
              " 'wall': 0.0,\n",
              " 'was': 0.0,\n",
              " 'we': 0.028688524590163935,\n",
              " 'weconstruct': 0.004098360655737705,\n",
              " 'wewill': 0.0,\n",
              " 'whenexpressed': 0.0,\n",
              " 'which': 0.012295081967213115,\n",
              " 'while': 0.004098360655737705,\n",
              " 'will': 0.0,\n",
              " 'with': 0.004098360655737705,\n",
              " 'without': 0.00819672131147541,\n",
              " 'wkb': 0.0,\n",
              " 'yieldagreement': 0.004098360655737705,\n",
              " 'yielded$0.997\\\\cdots$,': 0.004098360655737705,\n",
              " 'yields': 0.004098360655737705}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def computeIDF(docList):\n",
        "    import math\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "        \n",
        "    return idfDict    "
      ],
      "metadata": {
        "id": "1izu9I_6doHW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idfs = computeIDF([wordDictA, wordDictB])"
      ],
      "metadata": {
        "id": "dUUqu1H4dpoa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf"
      ],
      "metadata": {
        "id": "DEDHWdHodrdd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfBowA = computeTFIDF(tfBowA, idfs)\n",
        "tfidfBowB = computeTFIDF(tfBowB, idfs)"
      ],
      "metadata": {
        "id": "SuWfJ5EQdsyh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame([tfidfBowA, tfidfBowB])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "zufWPWw8duhX",
        "outputId": "822954b7-0ed6-4099-df53-d28334a9e39a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            norm  stationary.  thicknesssurrounding  ashtekar  actually  \\\n",
              "0  0.0  0.000000     0.001067              0.001067  0.000000  0.000000   \n",
              "1  0.0  0.001234     0.000000              0.000000  0.001234  0.001234   \n",
              "\n",
              "   moreover,  corresponding  earlier.        1,  ...  related  geometric   is  \\\n",
              "0   0.000000       0.001067  0.001067  0.000000  ...      0.0   0.001067  0.0   \n",
              "1   0.001234       0.000000  0.000000  0.001234  ...      0.0   0.000000  0.0   \n",
              "\n",
              "    immirzi  significant  whenexpressed  theright  article,  explicitly  \\\n",
              "0  0.000000     0.001067       0.001067  0.000000   0.00427    0.000000   \n",
              "1  0.001234     0.000000       0.000000  0.001234   0.00000    0.001234   \n",
              "\n",
              "   largecompared  \n",
              "0       0.001067  \n",
              "1       0.000000  \n",
              "\n",
              "[2 rows x 251 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e768b2e4-72d3-4ccb-a4f1-021003a27064\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>norm</th>\n",
              "      <th>stationary.</th>\n",
              "      <th>thicknesssurrounding</th>\n",
              "      <th>ashtekar</th>\n",
              "      <th>actually</th>\n",
              "      <th>moreover,</th>\n",
              "      <th>corresponding</th>\n",
              "      <th>earlier.</th>\n",
              "      <th>1,</th>\n",
              "      <th>...</th>\n",
              "      <th>related</th>\n",
              "      <th>geometric</th>\n",
              "      <th>is</th>\n",
              "      <th>immirzi</th>\n",
              "      <th>significant</th>\n",
              "      <th>whenexpressed</th>\n",
              "      <th>theright</th>\n",
              "      <th>article,</th>\n",
              "      <th>explicitly</th>\n",
              "      <th>largecompared</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00427</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 251 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e768b2e4-72d3-4ccb-a4f1-021003a27064')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e768b2e4-72d3-4ccb-a4f1-021003a27064 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e768b2e4-72d3-4ccb-a4f1-021003a27064');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}